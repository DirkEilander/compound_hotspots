{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook processes:\n",
    "- CaMa-Flood outputs to one zarr/netcdf containing daily waterlevels (per esemble member and experiment) and discharge (per ensemble member) at 3979 river mouth locations globally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from os.path import join\n",
    "from datetime import timedelta, datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ['anu', 'cnrs', 'ecmwf', 'nerc', 'jrc'] #, 'univu', 'univk']\n",
    "scenarios = ['msl', 'runoff', 'surge', 'tide', 'cmpnd']\n",
    "t0, t1 = datetime(1980,1,1), datetime(2014,12,31) # disregard last day. has some weird values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metadata and coupled indices\n",
    "root = r'/scratch/compound_hotspots'\n",
    "ddir = join(root, 'data', '4-postprocessed')\n",
    "fn_attrs = join(root, 'src', '1-prepare', 'rivmth+gtsm_attrs.csv')\n",
    "fn_coupling = join(root, 'src', '1-prepare', r'cmf_gtsm_75km.csv')\n",
    "t0, t1 = datetime(1980,1,1), datetime(2014,12,31) # disregard last day. has some weird values\n",
    "\n",
    "qmin = 0 # minimal longterm mean discharge [m3/s]\n",
    "attrs = pd.read_csv(fn_attrs, index_col=0)\n",
    "coupling = pd.read_csv(fn_coupling, index_col=0)\n",
    "print(len(attrs))\n",
    "attrs = attrs[attrs['q_mean'] > qmin]\n",
    "print(len(attrs))\n",
    "index = attrs.index.values\n",
    "\n",
    "rivmth_idx = coupling['rivmth_idx'].values # reindex to make sure it alligns\n",
    "gtsm_idx = coupling['gtsm_idx'].values\n",
    "coupling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine CaMa-Flood data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gtsm = xr.open_zarr(join(ddir, 'gtsm_day.zarr'))\n",
    "ds_cmf = xr.open_zarr(join(ddir, 'cmf.zarr'))\n",
    "ds = xr.merge([ds_gtsm, ds_cmf])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_cmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fn_format = join(ddir, '3-model_output', r'rivmth_{m}_mswep_{t}_v362_1980-2014.nc')\n",
    "\n",
    "# combine dstmth sensitivity runs \n",
    "# fn_out = join(out_dir, 'global_compound_rivmth_reanalysis_sensitivity.zarr')\n",
    "# fn_format = join(ddir, r'rivmth_anu_mswep_{t}_v362_1980-2014{m}.nc')\n",
    "# model = ['_dstmth8000', '', '_dstmth12000']\n",
    "# dstmth = np.array([8000, 10000, 12000])\n",
    "# out_chunks = {'time': -1, 'scen':-1, 'dstmth':-1, 'rivmth_id':100}\n",
    "\n",
    "# dataset coordinates\n",
    "rm_coords = {'id': 'rivmth_idx'}\n",
    "# chunks\n",
    "chunks = {'time': -1, 'id':100}\n",
    "\n",
    "# combine cmf outputs\n",
    "ds_m = []\n",
    "for m in model:\n",
    "    ds_t = []\n",
    "    for t in scenarios:\n",
    "        ds_t.append(xr.open_dataset(fn_format.format(m=m, t=t), chunks=chunks)[['sfcelv', 'outflw']].sortby('time'))\n",
    "    ds_t = xr.concat(ds_t, dim='scen')\n",
    "    ds_t['scen'] = xr.Variable(['scen'], np.asarray(scenarios).astype(str))\n",
    "    ds_m.append(ds_t)\n",
    "ds_cmf = xr.concat(ds_m, dim='ensemble').transpose('scen', 'ensemble', 'id', 'time')\n",
    "ds_cmf['ensemble'] = xr.Variable(['ensemble'], np.asarray(model).astype(str))\n",
    "ds_cmf['time'] = ds_cmf.time.to_index() + timedelta(days=-1)\n",
    "ds_cmf = ds_cmf.rename(**rm_coords).sel(rivmth_idx=coupling.rivmth_idx.values).drop(['lat_nc', 'lon_nc'])\n",
    "ds_cmf['index'] = xr.DataArray(dims=['rivmth_idx'], data=coupling.index.values, name='index')\n",
    "ds_cmf = ds_cmf.swap_dims({'rivmth_idx': 'index'})\n",
    "# ds_cmf\n",
    "fn_out = join(ddir, '4-postprocessed', 'cmf.zarr')\n",
    "chunks = {'ensemble':-1, 'scen':-1, 'time': -1, 'index':100}\n",
    "ds_cmf.chunk(chunks).to_zarr(fn_out, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gtsm = xr.open_zarr(join(ddir, 'gtsm_day.zarr'))\n",
    "ds_cmf = xr.open_zarr(join(ddir, 'cmf.zarr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_month_out = join(ddir, 'cmf', 'rivmth_msl.nc')\n",
    "# rm_clim = {\n",
    "#     'sfcelv': 'river_water_level_climatology', \n",
    "#     'outflw': 'river_discharge_climatology',\n",
    "# }\n",
    "# rm = {\n",
    "#     'sfcelv': 'river_water_level', \n",
    "#     'outflw': 'river_discharge',\n",
    "# }\n",
    "# ds_msl = ds_cmf.sel(scen='msl').drop(['scen'])\n",
    "# # climatology\n",
    "# ds_msl_clim = ds_msl.groupby('time.month').mean('time')\n",
    "# # broadcast to middle of month\n",
    "# ds_msl_month = xr.zeros_like(ds_msl).resample(time='SM').nearest()\n",
    "# ds_msl_month['time'] = ds_msl_month.time.to_index() + timedelta(days=15)\n",
    "# for v in ds_msl.data_vars.keys():\n",
    "#     ds_msl_month[v].data = ds_msl_month[v].groupby('time.month') + ds_msl_clim[v]\n",
    "# ds_msl_month = ds_msl_month.chunk({'time': -1, 'index': 100})\n",
    "# ds_clim_day = ds_msl_month.interp(time=ds_msl.time, method='linear')\n",
    "# ds_riv = xr.merge([\n",
    "#     ds_clim_day.rename(rm_clim),\n",
    "#     ds_msl.rename(rm),\n",
    "# ])\n",
    "\n",
    "# encoding = {v: {'zlib': True} for v in ds_riv.data_vars.keys()}\n",
    "# ds_riv.to_netcdf(fn_month_out, encoding=encoding)\n",
    "ds_riv = xr.open_dataset(fn_month_out).astype(np.float32)\n",
    "ds_riv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = ['runoff', 'surge', 'cmpnd']\n",
    "rm = {'sfcelv': 'water_level'}\n",
    "\n",
    "ds_rivmth = ds_cmf[['sfcelv']].sel(scen=scenarios).rename(rm)\n",
    "ds_rivmth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = ['runoff', 'surge', 'tide', 'cmpnd']\n",
    "\n",
    "ds_out = xr.merge([\n",
    "    ds_riv,\n",
    "    ds_sealvl,\n",
    "    ds_rivmth,\n",
    "]).sel(time=slice(t0,t1))\n",
    "\n",
    "# set and fix coordinates\n",
    "# select relevant stations and rename \n",
    "# cama saves outputs to next day 00:00AM\n",
    "# esemble metadata\n",
    "if 'ensemble' in ds_out.coords:\n",
    "    ds_out['ensemble'].attrs.update(\n",
    "        long_name = \"multi model ensemble\",\n",
    "        description = \"based on runoff forcing from Earth2Observe WRR2 hydrological models\"\n",
    "    )\n",
    "elif 'dstmth' in ds_out.coords:\n",
    "    ds_out['dstmth'].attrs.update(\n",
    "        long_name = \"downstream_boundary_distance\",\n",
    "        units = 'm'\n",
    "    )\n",
    "# scenarios\n",
    "ds_out['scen'].attrs.update(\n",
    "    long_name = \"scenarios\",\n",
    "    description = \"representing different flood drivers\"\n",
    ")\n",
    "\n",
    "# set cf conventions on variables\n",
    "ds_out['gtsm_idx'].attrs = dict(\n",
    "    long_name = \"GTSM station index of nearest station\",\n",
    "    units = \"-\",\n",
    "    grid_mapping = \"crs\"\n",
    ")\n",
    "\n",
    "for var in ds_out.data_vars.keys():\n",
    "    if 'discharge' in var:\n",
    "        if 'climatology' in var:\n",
    "            long_name = 'instantaneous discharge at GMT 00:00 daily',\n",
    "        else:\n",
    "            long_name = 'instantaneous discharge at GMT 00:00 daily',\n",
    "\n",
    "qattrs = dict(\n",
    "    standard_name = 'water_volume_transport_into_sea_water_from_rivers',\n",
    "    units = 'm3 s-1',\n",
    "    grid_mapping = \"crs\"\n",
    ")\n",
    "\n",
    "ds_out['river_discharge'].attrs.update(\n",
    "    long_name = 'instantaneous daily discharge at GMT 00:00 daily', \n",
    "    **qattrs\n",
    ")\n",
    "ds_out['river_discharge_climatology'] = ds_out['river_discharge_climatology'].astype(np.float32)\n",
    "ds_out['river_discharge_climatology'].attrs.update(\n",
    "    long_name = 'monthly discharge climatology', \n",
    "    **qattrs\n",
    ")\n",
    "\n",
    "\n",
    "wlattrs = dict(\n",
    "    standard_name = 'sea_water_surface_height_above_geoid',\n",
    "    units = 'm+egm96',\n",
    "    grid_mapping = \"crs\"\n",
    ")\n",
    "ds_out['water_level'].attrs.update(\n",
    "    long_name = 'instantaneous surface elevation at river mouth at GMT 00:00 daily',\n",
    "    **wlattrs\n",
    ")\n",
    "ds_out['river_water_level'].attrs.update(\n",
    "    long_name = 'instantaneous surface elevation at river mouth at GMT 00:00 daily assuming MSL boundary at 0m+egm96',\n",
    "    **wlattrs\n",
    ")\n",
    "ds_out['river_water_level_climatology'] = ds_out['river_water_level_climatology']\n",
    "ds_out['river_water_level_climatology'].attrs.update(\n",
    "    long_name = 'monthly river water level climatolgy ',\n",
    "    **wlattrs\n",
    ")\n",
    "ds_out['sea_water_level'] = ds_out['sea_water_level'].astype(np.float32)\n",
    "ds_out['sea_water_level'].attrs.update(\n",
    "    long_name = 'daily maximum nearshore still sea surface elevation',\n",
    "    **wlattrs\n",
    ")\n",
    "ds_out['sea_water_level_climatology'] = ds_out['sea_water_level_climatology'].astype(np.float32)\n",
    "ds_out['sea_water_level_climatology'].attrs.update(\n",
    "    long_name = 'monthly sea water level climatolgy ',\n",
    "    **wlattrs\n",
    ")\n",
    "\n",
    "# general attributes\n",
    "ds_out.attrs = dict(\n",
    "    title = 'global compound flood reanalysis data',\n",
    "    source = 'CaMa-Flood compound surge - discharge experiments',\n",
    "    institution = 'Institute for Environmental Studies (IVM) - Vrije Universiteit Amsterdam',\n",
    "    author = 'Dirk Eilander (dirk.eilander@vu.nl)',\n",
    "    conventions = \"CF-1.7\",\n",
    "    date_created = str(datetime.now().date()),\n",
    "    history = 'created using xarray v' + xr.__version__,\n",
    ")\n",
    "\n",
    "# save\n",
    "fn_out = join(ddir, 'gcfr.zarr')\n",
    "chunks = {'ensemble':-1, 'scen':-1, 'time': -1, 'index':100}\n",
    "ds_out.chunk(chunks).to_zarr(fn_out, mode='w')\n",
    "# ds_cmf.chunk(out_chunks).to_netcdf(fn_out.replace('.zarr', '.nc'), mode='w')\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_out = join(ddir, 'gcfr.zarr')\n",
    "ds_out = xr.open_zarr(fn_out)\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
