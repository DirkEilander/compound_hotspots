{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from os.path import join, basename\n",
    "from datetime import timedelta, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r'/scratch/compound_hotspots/'\n",
    "ddir = join(root, 'data', '3-model_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0, t1 = datetime(1980,1,2), datetime(2014,12,30)   # NOTE: cama date at 00hrs of 'next day' and missing GTSM values at 31-12-2014\n",
    "# scen_rm = {\n",
    "#     'cmpnd':   'surge', \n",
    "#     'runoff':  'seas',\n",
    "#     'tide':    'tide',\n",
    "#     'msl':     'msl'\n",
    "#     # 'surge':   'surge',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "chunks = {'time':3196, 'lat':30, 'lon':30}\n",
    "# regions = {\n",
    "#     'A': (-90.0, 41.0, -50.0, 65.0), # 40 x 24\n",
    "#     'B': (-12.0, 47.0, 18.0, 65.0), # 30 x 18\n",
    "#     'C': (70.0, -10.0, 130.0, 26.0),  # 60 x 36\n",
    "# }\n",
    "# name = 'B'\n",
    "# xmin, ymin, xmax, ymax = regions[name]\n",
    "\n",
    "for scen in ['cmpnd', 'runoff']:\n",
    "    fns = glob.glob(join(ddir, f'anu_mswep_{scen}_v362_1980-2014', 'sfcelv*.nc'))\n",
    "    fn_out = join(ddir, f'anu_mswep_{scen}_v362_1980-2014.zarr')\n",
    "    ds_sel = xr.open_mfdataset(fns, combine='by_coords', chunks=chunks).persist() #.sel(lon=slice(xmin, xmax), lat=slice(ymax, ymin))\n",
    "    with ProgressBar():\n",
    "        ds_sel.chunk(chunks).to_zarr(fn_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "map_dir = r'/home/dirk/models/cama-flood_bmi_v3.6.2_nc/map/global_15min'\n",
    "rm = {'x':'lon', 'y':'lat'}\n",
    "elevtn = xr.open_rasterio(join(map_dir, 'elevtn.tif')).drop('band').squeeze().rename(rm)\n",
    "lecz = xr.open_rasterio(join(map_dir, 'LEZC_10m_basin.tif')).drop('band').squeeze().rename(rm)\n",
    "# lecz = lecz.where(lecz>0)\n",
    "landmask = elevtn != -9999\n",
    "# # elevtn.where(lecz>0).plot(vmin=0, vmax=10, cmap='gist_earth')\n",
    "# elevtn.where(landmask).stack(latlon=('lat','lon')) #.dropna('latlon').unstack().reindex_like(elevtn).plot()\n",
    "# lecz_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "from peaks import get_peaks\n",
    "from xlm_fit import xlm_fit \n",
    "from lmoments3 import distr\n",
    "min_dist = 14\n",
    "chunks = {'time':-1, 'lat':30, 'lon':30}\n",
    "chunks2 = {'latlon':500, 'time':-1}\n",
    "rps_out = np.array([1.1, 1.5, 2, 5, 10, 20, 30, 50, 100])\n",
    "mask = lecz\n",
    "\n",
    "with ProgressBar():\n",
    "    for scen in ['cmpnd', 'runoff'][1:]:\n",
    "        print(scen)\n",
    "        #fn_out = join(ddir, f'anu_mswep_{scen}_v362_1980-2014', f'region{name}.zarr')\n",
    "        #ds = xr.open_zarr(fn_out)\n",
    "        # \n",
    "        fns = glob.glob(join(ddir, f'anu_mswep_{scen}_v362_1980-2014', 'sfcelv*.nc'))\n",
    "        da = xr.open_mfdataset(fns, combine='by_coords')['sfcelv']# #.sel(lon=slice(xmin, xmax), lat=slice(ymax, ymin))\n",
    "        da.coords['mask'] = mask\n",
    "        da_stacked = da.stack(latlon=('lat','lon'))\n",
    "        da_stacked = da_stacked.where(da_stacked['mask']>0, drop=True).chunk(chunks2)\n",
    "        # get AM\n",
    "        peaks_am_stacked = get_peaks(da_stacked, min_dist=min_dist, dim='time', chunks=chunks2).groupby('time.year').max('time')\n",
    "        peaks_am_stacked = peaks_am_stacked.rename({'year': 'time'}) #.persist()\n",
    "        #fn_out = join(ddir, f'anu_mswep_{scen}_v362_1980-2014', f'am_sfcelv.nc')\n",
    "        #print(basename(fn_out))\n",
    "        #peaks_am_stacked.unstack().to_netcdf(fn_out)\n",
    "        #peaks_am = xr.open_dataset(fn_out, chunks=chunks)\n",
    "        # fit gumbel\n",
    "        ds_rp_stacked = xlm_fit(peaks_am_stacked, fdist=distr.gum, rp=rps_out)\n",
    "        peaks_am_stacked.name = 'sfcelv_am'\n",
    "        ds_out = xr.merge([\n",
    "            peaks_am_stacked, ds_rp_stacked\n",
    "        ]).unstack().reindex_like(mask).chunk(chunks)\n",
    "        fn_out = join(ddir, f'anu_mswep_{scen}_v362_1980-2014', f'rp_sfcelv.nc')\n",
    "        print(basename(fn_out))\n",
    "        ds_out.to_netcdf(fn_out)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../4-analyze/'))\n",
    "from plot_tools import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import cartopy.crs as ccrs\n",
    "import seaborn as sns\n",
    "vmin, vmax, n= -0.2, 1.0, 7\n",
    "cticks=np.linspace(vmin, vmax, n)\n",
    "cmap_turbo_div = ListedColormap([\n",
    "    interpolate_cmap(google_turbo_data, x) for x in \n",
    "    np.hstack([np.linspace(0.55-(.4*abs(vmin)/vmax)*2, .55, int(-vmin*20)), np.linspace(0.6, 1, int(vmax*20))])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.open_dataset(join(ddir, f'anu_mswep_cmpnd_v362_1980-2014', f'rp_sfcelv.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swe_cmpnd = xr.open_dataset(join(ddir, f'anu_mswep_cmpnd_v362_1980-2014', f'rp_sfcelv.nc'))['sfcelv']\n",
    "swe_runoff = xr.open_dataset(join(ddir, f'anu_mswep_runoff_v362_1980-2014', f'rp_sfcelv.nc'))['sfcelv']\n",
    "swe_diff = (swe_cmpnd - swe_runoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = {\n",
    "    'A': (-90.0, 41.0, -50.0, 65.0), # 40 x 24\n",
    "    'B': (-12.0, 47.0, 18.0, 65.0), # 30 x 18\n",
    "    'C': (70.0, -10.0, 130.0, 26.0),  # 60 x 36\n",
    "}\n",
    "name = 'A'\n",
    "xmin, ymin, xmax, ymax = regions[name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import os \n",
    "\n",
    "map_dir = r'/home/dirk/models/cama-flood_bmi_v3.6.2_nc/map'\n",
    "sdir = join(map_dir, 'downscale_flddph')\n",
    "os.chdir(sdir)\n",
    "\n",
    "fn_elevtn = join(sdir, 'map', 'elevtn.tif')\n",
    "rm = {'x':'lon', 'y':'lat'}\n",
    "elevtn = xr.open_rasterio(fn_elevtn).drop('band').squeeze().rename(rm)\n",
    "\n",
    "fn_regions = join(sdir, 'map', 'hires', 'location.txt')\n",
    "regions = pd.read_csv(fn_regions, delim_whitespace=True, index_col=0).T \\\n",
    "            .set_index('area').astype(float).to_dict(orient='index')\n",
    "regions = {k:regions[k] for k in ['af1'] }\n",
    "# read nc\n",
    "fn = join(ddir, f'anu_mswep_runoff_v362_1980-2014', f'ev_map_sfcelv.nc')\n",
    "swe_runoff = xr.open_dataset(fn)['sfcelv_ev']\n",
    "flddph = swe_runoff - elevtn\n",
    "flddph = xr.where(flddph<0,0,flddph)\n",
    "\n",
    "mv=1e+20\n",
    "\n",
    "# write to bin\n",
    "for T in flddph['T'].values[2:]:\n",
    "    print(f'rp: {T:003.1f}')\n",
    "    data = flddph.fillna(mv).sel(T=T).data\n",
    "\n",
    "    fn_out_bin = join(sdir, f'flddph_T{T:03.0f}')\n",
    "    data.astype('f4').tofile(fn_out_bin)\n",
    "    \n",
    "    # downscale\n",
    "    for area in regions.keys():\n",
    "        print(area)\n",
    "        msg = ['./downscale_flddph', str(area), basename(fn_out_bin), '1']\n",
    "        subprocess.call(msg, cwd=sdir, stderr=subprocess.STDOUT)\n",
    "\n",
    "        # open binary output\n",
    "        fn_fld = join(sdir, '{:s}.flood'.format(area))\n",
    "        if os.path.isfile(fn_fld):\n",
    "            ny, nx = int(regions[area]['ny']), int(regions[area]['nx'])\n",
    "            with open(fn_fld, 'r') as fid:\n",
    "                data = np.fromfile(fid, 'f4').reshape(ny, nx)\n",
    "                data = np.where(data==mv, -9999, data)\n",
    "\n",
    "            # write to geotiff\n",
    "            fn_out_tif = join(ddir, f'anu_mswep_runoff_v362_1980-2014', 'flddph', f'{area}_T{T:03.0f}.tif')\n",
    "            west, north, csize = regions[area]['west'], regions[area]['north'], regions[area]['csize']\n",
    "            transform = from_origin(west, north, csize, csize)\n",
    "            with rasterio.open(fn_out_tif, 'w', driver='GTiff', height=data.shape[0],\n",
    "                        compress='lzw', width=data.shape[1], count=1, dtype=str(data.dtype),\n",
    "                        crs='+proj=latlong', transform=transform, nodata=-9999) as dst:\n",
    "                dst.write(data, 1)\n",
    "\n",
    "            # remove binary output\n",
    "            os.unlink(fn_fld)\n",
    "        else:\n",
    "            print(' '.join(msg))\n",
    "    os.unlink(fn_out_bin)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def build_vrt(fn_vrt, fns, bbox=None, nodata=None):\n",
    "    from osgeo import gdal\n",
    "    vrt_options = gdal.BuildVRTOptions(\n",
    "        outputBounds=bbox, \n",
    "        srcNodata=nodata, \n",
    "        VRTNodata=nodata\n",
    "    )\n",
    "    if os.path.isfile(fn_vrt):\n",
    "        os.remove(fn_vrt)\n",
    "    vrt = gdal.BuildVRT(fn_vrt, fns, options=vrt_options)\n",
    "    if vrt is None:\n",
    "        raise Exception('Creating vrt not successfull, check input files.')\n",
    "    vrt = None # to write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = glob.glob(join(ddir, f'anu_mswep_runoff_v362_1980-2014', 'flddph', f'*_T005.tif'))\n",
    "fn_vrt = join(ddir, f'anu_mswep_runoff_v362_1980-2014', 'flddph', f'T005.vrt')\n",
    "bbox = -180, -90, 180, 90\n",
    "nodata = -9999\n",
    "build_vrt(fn_vrt, fns, bbox, nodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps = [2, 5]\n",
    "ds_lst = []\n",
    "chunks={'x':7200, 'y':7200}\n",
    "for T in rps:\n",
    "    fn_vrt = join(ddir, f'anu_mswep_runoff_v362_1980-2014', 'flddph', f'T{T:03.0f}.vrt')\n",
    "    ds_lst.append(xr.open_rasterio(fn_vrt, chunks=chunks).drop('band').squeeze().rename({'x':'lon', 'y':'lat'}))\n",
    "flddph = xr.concat(ds_lst, dim='T')\n",
    "flddph.coords['T'] = xr.Variable('T', rps)\n",
    "flddph.name = 'flddph'\n",
    "fn_out = join(ddir, f'anu_mswep_runoff_v362_1980-2014', 'flddph_highres.nc')\n",
    "flddph.to_netcdf(fn_out, encoding={'flddph': {'zlib': True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(1,1, figsize=(15,15))\n",
    "flddph = xr.open_rasterio(fn_vrt).squeeze().rename({'x':'lon', 'y':'lat'})\n",
    "xmin, ymin, xmax, ymax = -11.55,49.74,2.38,59.64\n",
    "flddph_sel = flddph.sel(lat=slice(ymax, ymin), lon=slice(xmin, xmax))\n",
    "flddph_sel = flddph_sel.where(flddph_sel!=-9999)\n",
    "flddph_sel.plot(vmin=0, vmax=2, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,1, figsize=(20,10))\n",
    "flddph.sel(T=50.).plot(ax=ax, vmin=0, vmax=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1, figsize=(10,10))\n",
    "swe_diff0 = swe_diff.sel(lat=slice(ymax,ymin), lon=slice(xmin,xmax))\n",
    "swe_diff0.where(xr.ufuncs.fabs(swe_diff)>0.01).sel(T=100).plot(ax=ax, vmin=vmin, vmax=vmax, cmap=cmap_turbo_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'A'\n",
    "ds = xr.concat([\n",
    "    xr.open_dataset(join(ddir, f'anu_mswep_{scen}_v362_1980-2014', f'region{name}_rp.nc')) \n",
    "    for scen in ['cmpnd', 'runoff']\n",
    "], dim='scen')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "da_swe_diff = -ds['sfcelv'].where(ds['sfcelv']>0).diff('scen').squeeze()\n",
    "da_swe_diff = da_swe_diff.where(xr.ufuncs.fabs(da_swe_diff)>0.01)\n",
    "da_swe_diff.sel(T=20.).plot(cmap=cmap_turbo_div, vmin=vmin, vmax=vmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
