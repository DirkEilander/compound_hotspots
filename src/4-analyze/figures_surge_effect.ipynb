{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "from os.path import join, basename\n",
    "from datetime import date, datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../3-postprocess/'))\n",
    "import xstats as xs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from plot_tools import *\n",
    "import cartopy.crs as ccrs\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r'/scratch/compound_hotspots'\n",
    "ddir = join(root, 'data', '4-postprocessed')\n",
    "fdir = join(root, 'reports', 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = {'savefig.bbox': 'tight',  'savefig.format': 'png', 'savefig.dpi':300}\n",
    "context = 'paper'\n",
    "# sns.set(context=context, style='whitegrid', font_scale=0.75 if context == 'talk' else 1., rc=rc)\n",
    "sns.set(context=context, style='whitegrid', font_scale=1.2 if context == 'paper' else 1., rc=rc)\n",
    "s=30\n",
    "crs = ccrs.Robinson()\n",
    "crs_sub = ccrs.PlateCarree()\n",
    "cmap_div = sns.diverging_palette(220, 10, s=75, l=40, sep=1, as_cmap=True)\n",
    "cmap_turbo_div = ListedColormap([\n",
    "    interpolate_cmap(google_turbo_data, x) for x in \n",
    "    np.hstack([np.linspace(0.1, .35, 50), np.linspace(0.6, 0.9, 50)])\n",
    "])\n",
    "\n",
    "bmap_kwargs = dict()\n",
    "#     features=['land', 'rivers'],\n",
    "#     feat_colors = [cfeature.COLORS['land_alt1'], cfeature.COLORS['water']],\n",
    "# )\n",
    "\n",
    "plot_kwargs=dict(edgecolor=(0.5, 0.5, 0.5, 0.8), linewidth=0.5, legend=False, zorder=2)\n",
    "box_kwargs=dict(whis=[5,95], boxprops=dict(linewidth=1.), medianprops=dict(linewidth=1.5), \n",
    "                showfliers=False, flierprops=dict(markersize=2))\n",
    "\n",
    "\n",
    "from string import ascii_uppercase as letters\n",
    "\n",
    "locs = [1930, 1618, 809]\n",
    "riv_names = {\n",
    "    809: 'Mattapone', \n",
    "    1695: 'Weser',\n",
    "    1930: 'Dal',\n",
    "    1618: 'Volta',  \n",
    "    2884: 'Ataran',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def spearmanr(da0, da1, dim='time'):\n",
    "    def _spearmanr(a, b):\n",
    "        return np.asarray(scipy.stats.spearmanr(a,b))\n",
    "    # apply_ufunc parameters\n",
    "    kwargs = dict(               \n",
    "        input_core_dims=[[dim], [dim]], \n",
    "        output_core_dims=[['stats']],\n",
    "        dask='parallelized',\n",
    "        output_dtypes=[float],    \n",
    "        output_sizes={'stats': 2}, # on output, <dim> is reduced to length q.size \n",
    "        vectorize=True\n",
    "    )\n",
    "    da_out = xr.apply_ufunc(_spearmanr, da0, da1, **kwargs)\n",
    "    da_out['stats'] = xr.Variable('stats', ['r', 'p'])\n",
    "    return da_out.sel(stats='r').drop('stats'), da_out.sel(stats='p').drop('stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def weibull(peaks, nyears=None):\n",
    "    peaks = peaks[np.isfinite(peaks)]\n",
    "    peaks_rank = rankdata(peaks, 'ordinal')\n",
    "    P = peaks_rank/(peaks.size+1)\n",
    "    freq = 1. if nyears is None else peaks.size / nyears\n",
    "    rp = 1/(1-P)/freq\n",
    "    return rp\n",
    "\n",
    "def _interp_ev(peaks, vals, nyears=None):\n",
    "    peaks = peaks[np.isfinite(peaks)]\n",
    "    peaks.sort()\n",
    "    peaks_rank = np.arange(peaks.size)+1\n",
    "    P = peaks_rank/(peaks.size+1)\n",
    "    freq = 1. if nyears is None else peaks.size / nyears\n",
    "    rp = 1/(1-P)/freq\n",
    "    kwargs = dict(\n",
    "        kind='linear', bounds_error=False, assume_sorted=True,\n",
    "        fill_value=(rp.min(), rp.max())\n",
    "    )\n",
    "    rp_out = interp1d(peaks, rp, **kwargs)(vals)\n",
    "    return rp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs_fn = join(ddir, 'rivmth_mean_attrs.csv')\n",
    "attrs = pd.read_csv(attrs_fn, index_col='index').rename(columns={'rivmth_lat':'lat', 'rivmth_lon':'lon'}).drop(3354)\n",
    "\n",
    "attrs['uparea_log10'] = np.log10(np.maximum(attrs['uparea'].values, 0.001))\n",
    "attrs['Hseasrange'] = attrs['Hseas_amax']-attrs['Hseas_amin']\n",
    "attrs['mean_drain_length'] = attrs['mean_drain_length']/1e3 #[km]\n",
    "attrs['mean_drain_slope'] = attrs['mean_drain_slope']*1e3 #[m/km]\n",
    "attrs['uparea_100'] = attrs['uparea']/1e2\n",
    "attrs['Hseasrange_cm'] = attrs['Hseasrange']*1e2\n",
    "attrs['Hseas_amax_cm'] = attrs['Hseas_amax']*1e2\n",
    "attrs['Hsurge_amax_cm'] = attrs['Hsurge_amax']*1e2\n",
    "attrs['Q_amax_10'] = attrs['Q_amax']/10\n",
    "attrs['Q_amax_norm'] = attrs['Q_amax']/attrs['Q_mean']\n",
    "attrs['Hskewsurge_amax_cm'] = attrs['Hskewsurge_amax']*1e2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_rivmth_ts = join(ddir, 'rivmth_reanalysis.zarr')\n",
    "ds = xr.open_zarr(fn_rivmth_ts).sel(scen='msl', index=attrs.index)\n",
    "\n",
    "da_Q = ds['Q']\n",
    "da_Q_am = da_Q.groupby('time.year').max('time')\n",
    "da_Q_am_avg = da_Q_am.mean('year')\n",
    "da_Q_am_std = da_Q_am.std('year')\n",
    "da_Q_am_cv = da_Q_am_std / da_Q_am_avg\n",
    "\n",
    "attrs['Q_amax'] = da_Q_am_avg.mean('ensemble')\n",
    "attrs['Q_amax_cv'] = da_Q_am_cv.mean('ensemble')\n",
    "attrs['Q_mean'] = da_Q.mean('time').mean('ensemble')\n",
    "\n",
    "da_Hskewsurge = ds['Hskewsurge_day']\n",
    "da_Hskewsurge_am = da_Hskewsurge.groupby('time.year').max('time')\n",
    "attrs['Hskewsurge_amax'] = da_Hskewsurge_am.mean('year')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read rp, peaks and impact results\n",
    "wdw = 1\n",
    "fn_rivmth_ts = join(ddir, 'rivmth_reanalysis.zarr')\n",
    "fn_peaks_wdw = join(ddir, f'rivmth_h_am_wdw{wdw}.nc')\n",
    "fn_peaks_rp_ci = join(ddir, f'rivmth_swe_am_ci.nc')\n",
    "fn_impact = join(ddir, 'rivmth_pop_affected.nc')\n",
    "model='mean'\n",
    "\n",
    "ds_rp = xr.open_dataset(fn_peaks_rp_ci).drop_sel(index=3354)#.sel(ensemble=[model])\n",
    "ds_impact = xr.open_dataset(fn_impact).drop_sel(index=3354)#.sel(ensemble=[model])\n",
    "ds_peaks = xr.open_dataset(fn_peaks_wdw).drop_sel(index=3354)#.sel(ensemble=[model])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:              (T: 4, ensemble: 5, index: 3433)\n",
       "Coordinates:\n",
       "  * index                (index) int64 0 1 2 3 4 5 ... 3973 3975 3976 3977 3978\n",
       "  * ensemble             (ensemble) object &#x27;anu&#x27; &#x27;cnrs&#x27; &#x27;ecmwf&#x27; &#x27;jrc&#x27; &#x27;nerc&#x27;\n",
       "  * T                    (T) int64 2 10 50 100\n",
       "Data variables:\n",
       "    people_affected_dH   (ensemble, T, index) float32 ...\n",
       "    people_affected_all  (ensemble, T, index) float32 ...\n",
       "    people_all           (index) float32 ...\n",
       "    people_lecz          (index) float32 ...</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:              (T: 4, ensemble: 5, index: 3433)\n",
       "Coordinates:\n",
       "  * index                (index) int64 0 1 2 3 4 5 ... 3973 3975 3976 3977 3978\n",
       "  * ensemble             (ensemble) object 'anu' 'cnrs' 'ecmwf' 'jrc' 'nerc'\n",
       "  * T                    (T) int64 2 10 50 100\n",
       "Data variables:\n",
       "    people_affected_dH   (ensemble, T, index) float32 ...\n",
       "    people_affected_all  (ensemble, T, index) float32 ...\n",
       "    people_all           (index) float32 ...\n",
       "    people_lecz          (index) float32 ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in rp\n",
    "alpha=0.025\n",
    "\n",
    "da_wse_rps_ci = ds_rp['WSE_ev_ci']\n",
    "da_wse_rps = ds_rp['WSE_ev']\n",
    "    \n",
    "# diff\n",
    "diff_surge_seas = (da_wse_rps.sel(scen='surge') - da_wse_rps.sel(scen='seas'))\n",
    "diff_surge_seas.name = 'diff_h_surge_seas'\n",
    "diff_seas_tide = (da_wse_rps.sel(scen='seas') - da_wse_rps.sel(scen='tide'))\n",
    "diff_seas_tide.name = 'diff_h_seas_tide'\n",
    "diff_surge_tide = (da_wse_rps.sel(scen='surge') - da_wse_rps.sel(scen='tide'))\n",
    "diff_surge_tide.name = 'diff_h_surge_tide'\n",
    "ds_diff = xr.merge([\n",
    "    diff_surge_seas,\n",
    "    diff_seas_tide,\n",
    "    diff_surge_tide,\n",
    "])\n",
    "\n",
    "dim = 'ensemble'\n",
    "# average and calculate significance based on std error\n",
    "N = ds_diff[dim].size\n",
    "ds_diff_mean = ds_diff.mean(dim)\n",
    "ds_diff_dir =  xr.ufuncs.fabs(xr.ufuncs.sign(ds_diff).sum(dim)) == N\n",
    "# ds_diff_sign = xr.ufuncs.fabs(ds_diff_mean / ds_diff.std(dim)) > (2 / xr.ufuncs.sqrt(N-1))\n",
    "\n",
    "ds_lst = []\n",
    "for var in list(ds_diff.data_vars.keys()):\n",
    "    v2,v3 = var.split('_')[-2:]\n",
    "    da_sign = xr.where(\n",
    "        xr.ufuncs.sign(ds_diff[var])>0,\n",
    "        da_wse_rps_ci.sel(scen=v2, alpha=alpha) > da_wse_rps_ci.sel(scen=v3, alpha=1-alpha),\n",
    "        da_wse_rps_ci.sel(scen=v3, alpha=alpha) > da_wse_rps_ci.sel(scen=v2, alpha=1-alpha),\n",
    "    )#.drop('alpha')\n",
    "    da_sign.name = var\n",
    "    ds_lst.append(da_sign)\n",
    "ds_diff_sign2 = xr.merge(ds_lst).sum('ensemble') >= N\n",
    "\n",
    "ds_diff_h_stats = xr.merge([\n",
    "    ds_diff_mean,\n",
    "    ds_diff_dir.rename({v:f'{v}_sign' for v in ds_diff_dir.data_vars.keys()}),\n",
    "    np.logical_and(ds_diff_sign2, ds_diff_dir).rename({v:f'{v}_sign_ci' for v in ds_diff_dir.data_vars.keys()}),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference in scale and loc parameters\n",
    "da_scale = ds_rp['params'].sel(par='scale').drop('par')\n",
    "da_loc = ds_rp['params'].sel(par='loc').drop('par')\n",
    "    \n",
    "# diff\n",
    "offset = attrs['gtsm_egm_offset'].to_xarray()\n",
    "dscale_surge_tide = (da_scale.sel(scen='surge') - da_scale.sel(scen='tide'))\n",
    "dscale_surge_tide.name = 'diff_scale_surge_tide'\n",
    "dloc_surge_tide = (da_loc.sel(scen='surge') - da_loc.sel(scen='tide'))\n",
    "dloc_surge_tide.name = 'diff_loc_surge_tide'\n",
    "dscale_surge_seas = (da_scale.sel(scen='surge') - da_scale.sel(scen='seas'))\n",
    "dscale_surge_seas.name = 'diff_scale_surge_seas'\n",
    "dloc_surge_seas = (da_loc.sel(scen='surge') - da_loc.sel(scen='seas'))\n",
    "dloc_surge_seas.name = 'diff_loc_surge_seas'\n",
    "dscale_seas_tide = (da_scale.sel(scen='seas') - da_scale.sel(scen='tide'))\n",
    "dscale_seas_tide.name = 'diff_scale_seas_tide'\n",
    "dloc_seas_tide = (da_loc.sel(scen='seas') - da_loc.sel(scen='tide'))\n",
    "dloc_seas_tide.name = 'diff_loc_seas_tide'\n",
    "\n",
    "ds_diff = xr.merge([\n",
    "    dscale_surge_tide,\n",
    "    dloc_surge_tide,\n",
    "    dscale_surge_seas,\n",
    "    dloc_surge_seas,\n",
    "    dscale_seas_tide,\n",
    "    dloc_seas_tide,\n",
    "])\n",
    "\n",
    "dim = 'ensemble'\n",
    "# average and calculate significance based on std error\n",
    "N = ds_diff[dim].size\n",
    "ds_diff_mean = ds_diff.mean(dim)\n",
    "ds_diff_dir =  xr.ufuncs.fabs(xr.ufuncs.sign(ds_diff).sum(dim)) == N\n",
    "# ds_diff_sign = xr.ufuncs.fabs((ds_diff_mean-1) / ds_diff.std(dim)) > (2 / xr.ufuncs.sqrt(N-1))\n",
    "# var = 'diff_surge_tide'\n",
    "# ds_diff_sign = ds_diff_stats[var].sel(T=rp, stat='sign').drop('stat')\n",
    "\n",
    "ds_diff_par_stats = xr.merge([\n",
    "    ds_diff_mean,\n",
    "    ds_diff_dir.rename({v:f'{v}_sign' for v in ds_diff_dir.data_vars.keys()}),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = ['Hskewsurge','Q']\n",
    "\n",
    "ds_spear = ds_peaks.coords.to_dataset().drop(['year'])\n",
    "for d in drivers:\n",
    "    ds_spear[f'{d}_r'], ds_spear[f'{d}_p'] = spearmanr(ds_peaks['h'], ds_peaks[d], dim='year')\n",
    "\n",
    "ds_spear['H'] = np.logical_and(ds_spear[f'{drivers[0]}_r']>=0.0, ds_spear[f'{drivers[0]}_p']<=0.05)\n",
    "ds_spear['Q'] = np.logical_and(ds_spear[f'{drivers[1]}_r']>=0.0, ds_spear[f'{drivers[1]}_p']<=0.05)\n",
    "ds_spear['insign'] = np.logical_and(~ds_spear['H'], ~ds_spear['Q'])\n",
    "ds_spear['compound'] = np.logical_and(ds_spear['H'], ds_spear['Q'])\n",
    "\n",
    "N = ds_spear['ensemble'].size\n",
    "N2 = int(np.ceil(N/2))\n",
    "Hsign1 = ds_spear['H'].sum('ensemble') >= N2\n",
    "Qsign1 = ds_spear['Q'].sum('ensemble') >= N2\n",
    "compound1 = ds_spear['compound'].sum('ensemble') >= N2\n",
    "insign1 = ds_spear['insign'].sum('ensemble') >= N2\n",
    "\n",
    "ds_corr_stats = ds_peaks.coords.to_dataset().drop(['year', 'ensemble'])\n",
    "ds_corr_stats['driver_H_sign'] = Hsign1\n",
    "ds_corr_stats['driver_Q_sign'] = Qsign1\n",
    "ds_corr_stats['driver_H_r'] = ds_spear[f'{drivers[0]}_r'].mean('ensemble')\n",
    "ds_corr_stats['driver_Q_r'] = ds_spear[f'{drivers[1]}_r'].mean('ensemble')\n",
    "# if N>1:\n",
    "#     ds_corr_stats[f'driver_compound_(N={N})'] = ds_spear['compound'].sum('ensemble') >= N\n",
    "ds_corr_stats[f'driver_compound'] = compound1\n",
    "ds_corr_stats['driver_H'] = np.logical_and(np.logical_and(Hsign1, ~Qsign1), ~compound1)\n",
    "ds_corr_stats['driver_Q'] = np.logical_and(np.logical_and(Qsign1, ~Hsign1), ~compound1)\n",
    "ds_corr_stats['driver_insign'] = np.logical_and(np.logical_and(~ds_corr_stats['driver_Q'], ~ds_corr_stats['driver_H']), ~compound1)\n",
    "corr_sum = (ds_corr_stats.drop(['driver_H_r', 'driver_Q_r', 'driver_H_sign', 'driver_Q_sign']).sum()/ds_corr_stats.index.size*100).expand_dims('index').to_dataframe()\n",
    "print(corr_sum.values.sum())\n",
    "corr_sum.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T0 = xr.DataArray(\n",
    "    dims=('ensemble', 'T', 'index'), \n",
    "    coords={'ensemble':ds_impact.ensemble, 'T': [1], 'index': ds_impact.index}, \n",
    "    data=np.zeros((ds_impact.ensemble.size,1,ds_impact.index.size))\n",
    ")\n",
    "pop_affected_dH_dp = xr.concat([T0, ds_impact['people_affected_dH']], dim='T')\n",
    "pop_affected_dH_dp['p'] = xr.Variable('T', 1/pop_affected_dH_dp['T'].values)\n",
    "pop_affected_dH_dp = pop_affected_dH_dp.sel(T=pop_affected_dH_dp['T'].values[::-1]).swap_dims({'T':'p'}) \n",
    "ds_impact['people_affected_dH_dp'] = pop_affected_dH_dp.integrate('p')\n",
    "pop_affected_all_dp = xr.concat([T0, ds_impact['people_affected_all']], dim='T')\n",
    "pop_affected_all_dp['p'] = xr.Variable('T', 1/pop_affected_all_dp['T'].values)\n",
    "pop_affected_all_dp = pop_affected_all_dp.sel(T=pop_affected_all_dp['T'].values[::-1]).swap_dims({'T':'p'}) \n",
    "ds_impact['people_affected_all_dp'] = pop_affected_all_dp.integrate('p')\n",
    "ds_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = 10\n",
    "ds_stats = xr.merge([ds_diff_h_stats, \n",
    "#                      ds_diff_par_stats, \n",
    "                     ds_impact.mean('ensemble'), ds_corr_stats])\n",
    "gdf = pandas2geopandas(pd.concat([\n",
    "    attrs,\n",
    "    ds_stats.sel(T=rp).reset_coords(drop=True).to_dataframe()\n",
    "], axis=1))\n",
    "gdf['people_affected_dH_perc'] = gdf['people_affected_dH'] /  np.maximum(gdf['people_affected_all'],1) * 100\n",
    "gdf['people_affected_dH_dp_perc'] = gdf['people_affected_dH_dp'] /  np.maximum(gdf['people_affected_all_dp'],1) * 100\n",
    "gdf['people_affected_dH_dp_percLECZ'] = np.minimum(gdf['people_affected_dH_dp'] / np.maximum(gdf['people_lecz'],1) * 100, 100)\n",
    "gdf['people_affected_dH_dp_percALL'] = gdf['people_affected_dH_dp'] /  np.maximum(gdf['people_all'],1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 'h'\n",
    "scen = 'surge_tide'\n",
    "gdf['diff_class'] = np.logical_and(gdf[f'diff_{param}_{scen}_sign'], gdf[f'diff_{param}_{scen}']>0) * 1 +\\\n",
    "                    np.logical_and(gdf[f'diff_{param}_{scen}_sign'], gdf[f'diff_{param}_{scen}']<0) * 2\n",
    "gdf1 = gdf[['diff_class', f'diff_{param}_{scen}']] #, 'diff_h_surge_tide', 'Q_amax', 'Hskewsurge_amax', 'Hsurge_amax', 'Hseasrange', 'Htiderange_amax']]\n",
    "print(gdf1.groupby('diff_class')['diff_class'].count()/gdf.index.size*100)\n",
    "# print(gdf1.mean())\n",
    "gdf1.groupby('diff_class').mean() #g1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlst = [f'compound', 'H', 'Q', 'insign']\n",
    "da_d = xr.concat([ds_spear[[f'{d}_r' for d in drivers]].where(ds_spear[d]).mean('index') for d in dlst], dim='driver').rename({f'{drivers[0]}_r': 'H_r' })\n",
    "da_d['driver'] = xr.Variable('driver', [d for d in dlst])\n",
    "da_d_all = xr.concat([ds_corr_stats[['driver_H_r', 'driver_Q_r']].where(ds_corr_stats[f'driver_{d}']).mean('index') for d in dlst], dim='driver').expand_dims('ensemble')\n",
    "da_d_all = da_d_all.rename({v:v.replace('driver_','') for v in da_d_all.data_vars.keys()})\n",
    "da_d_all['driver'] = xr.Variable('driver', [d for d in dlst])\n",
    "da_d_all['ensemble'] = xr.Variable('ensemble', ['_N3'])\n",
    "xr.concat([da_d, da_d_all], dim='ensemble').to_dataframe().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_d = xr.concat([ds_spear[f'{d}'].where(~ds_spear['compound']).sum('index') if d != 'compound' else ds_spear[f'{d}'].sum('index')\n",
    "                  for d in dlst], dim='driver')\n",
    "da_d_all = xr.concat([ds_corr_stats[f'driver_{d}'].sum('index') for d in dlst], dim='driver').expand_dims('ensemble')\n",
    "da_d_all['driver'] = xr.Variable('driver', [d for d in dlst])\n",
    "da_d_all['ensemble'] = xr.Variable('ensemble', ['_N3'])\n",
    "xr.concat([da_d, da_d_all], dim='ensemble').to_dataframe().unstack() / ds_spear.index.size * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['driver'] = gdf['driver_H']+gdf['driver_Q']*2+gdf[f'driver_compound']*3+gdf[f'driver_insign']*4\n",
    "gdf1 = gdf[gdf['diff_h_surge_tide_sign']==1]\n",
    "gdf[['driver', 'diff_h_surge_tide', 'diff_h_surge_seas', 'diff_h_seas_tide']].groupby('driver').mean()\n",
    "gdf[['driver', 'people_affected_dH']].groupby('driver').sum() #/ gdf[['driver', 'people_lecz']].groupby('driver').sum().values\n",
    "gdf[['driver', 'people_affected_all']].groupby('driver').sum()/ gdf[['driver', 'people_affected_all']].groupby('driver').sum().values.sum()\n",
    "gdf[['driver', 'people_affected_dH']].groupby('driver').sum()/ gdf[['driver', 'people_affected_all']].groupby('driver').sum().values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_dH = (ds_stats['diff_h_surge_tide_sign']==1).sel(T=ds_impact['T'])\n",
    "pop_affected_dH = ds_impact['people_affected_dH'].where(sign_dH).sum('index')\n",
    "pop_affected_all = ds_impact['people_affected_all'].where(sign_dH).sum('index')\n",
    "pop_lecz = ds_impact['people_lecz'].sum('index').expand_dims('index')\n",
    "pop_all = ds_impact['people_all'].sum('index').expand_dims('index')\n",
    "df = (pop_affected_dH/pop_affected_all*100).to_series().unstack(0)\n",
    "df['mean'] = df.mean(axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (ds_impact['people_affected_dH_dp'].sum('index')/ds_impact['people_affected_all_dp'].sum('index')*100).to_series()\n",
    "df['mean'] = df.mean()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## location plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scen_cmap = {\n",
    "    'surge': np.asarray(plt.cm.tab10.colors[0]), \n",
    "    'seas': np.asarray(plt.cm.tab10.colors[3]), \n",
    "    'tide': np.asarray(plt.cm.tab10.colors[4])\n",
    "}\n",
    "scen_mmap  = {'surge': 'o', 'seas': '^', 'tide': 'd'}\n",
    "scen_nmap  = {'seas': 'seasonal'}\n",
    "\n",
    "plt.close('all')\n",
    "model2=model if model != 'mean' else 'nerc'\n",
    "xlim = [0.9,40]\n",
    "rps2 = [1, 2, 4, 8, 16, 32]\n",
    "shape=(1,len(locs))\n",
    "fig = plt.figure(figsize=(len(locs)*4, 3.5))\n",
    "grid = plt.GridSpec(*shape, hspace=0.1, wspace=0.2)\n",
    "axes =[]\n",
    "for irow in range(shape[0]):\n",
    "    for icol in range(shape[1]):\n",
    "        axes.append(fig.add_subplot(grid[irow, icol]))\n",
    "    \n",
    "posn = axes[-1].get_position()\n",
    "axg = fig.add_axes([posn.x1+0.01, posn.y0-0.2, posn.width*0.8, posn.height], projection=crs_sub) # new ax   \n",
    "basemap(axg, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, features=['land'])\n",
    "gdf.loc[locs,:].plot(ax=axg, marker='o', color='red', markersize=50, legend=True)\n",
    "attrs['z0'] = 0 #attrs['elevtn']-attrs['rivhgt']\n",
    "\n",
    "for i, loc in enumerate(locs):\n",
    "    name = riv_names.get(loc, 'unknown')\n",
    "    gdf_loc = gdf.loc[loc,:]    \n",
    "    irow = i // shape[1]\n",
    "    icol = i % shape[1]\n",
    "    ax = axes[i]\n",
    "    \n",
    "    ds_ev_loc = ds_rp.sel(index=loc)\n",
    "    z0 = attrs.loc[loc, 'z0']\n",
    "    T = ds_ev_loc.T.values\n",
    "    for scen in ['surge', 'seas', 'tide'][::-1]:\n",
    "        _ds = ds_ev_loc.sel(scen=scen, ensemble=model2)\n",
    "        peaks_am = _ds['WSE_am'].values-z0\n",
    "        Tpeaks_am = weibull(peaks_am)\n",
    "        ev_ci = _ds['WSE_ev_ci'].sel(alpha=[alpha, 1-alpha]).values - z0\n",
    "        ev = _ds['WSE_ev'].values - z0\n",
    "        ax.scatter(Tpeaks_am, peaks_am, c=scen_cmap[scen], marker=scen_mmap[scen], label=scen_nmap.get(scen, scen), zorder=2)\n",
    "        ax.plot(T, ev, color=scen_cmap[scen], zorder=1)\n",
    "        ax.plot(T, ev_ci[0,:], color=scen_cmap[scen], linestyle='-.', alpha=0.4, zorder=0)\n",
    "        ax.plot(T, ev_ci[1,:], color=scen_cmap[scen], linestyle='-.', alpha=0.4, zorder=0)\n",
    "    ax.set_xscale('log')\n",
    "    if irow == 0:\n",
    "        ax.set_xticks(rps2)\n",
    "        ax.set_xticklabels(rps2)\n",
    "        ax.set_xlabel('return period [years]')\n",
    "    else:\n",
    "        ax.set_xticks(rps2)\n",
    "        ax.set_xticklabels([])\n",
    "    if icol == 0:\n",
    "        ax.set_ylabel('water surface elevation [m+EGM96]')\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.grid(False)\n",
    "\n",
    "    l = letters[i]\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.text(xlim[0], ymax+(ymax-ymin)*0.01, f'{l}. {name} River', fontsize='large')\n",
    "    x, y = gdf_loc.geometry.coords[0]\n",
    "    axg.text(x+10, y, letters[i], transform=crs_sub)\n",
    "    \n",
    "    ax.grid(False)\n",
    "\n",
    "ax.legend(loc='lower left', bbox_to_anchor=(1.05, 0.5), title='sea boundary')\n",
    "\n",
    "fn_fig = join(fdir, f'locs_rivmth_peaks_gumb_ci{alpha}_{model2}.png')\n",
    "print(basename(fn_fig))\n",
    "plt.savefig(fn_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "from scipy.interpolate import interp1d\n",
    "from peaks import get_peaks\n",
    "rm = {'Hskewsurge_day':'Hskewsurge', 'Htot_day_max': 'Htot', 'Htide_day_max': 'Htide', 'Hsurge_day_max': 'Hsurge'}\n",
    "ds = xr.open_zarr(fn_rivmth_ts).sel(scen='surge').drop(['Hsurge', 'Htide']).rename(rm)\n",
    "ds1 = ds.sel(time=slice('01-01-2000', '31-12-2014'))\n",
    "\n",
    "rps = np.array([0.2, 1, 2, 4, 8, 16, 32])\n",
    "# cmap = ListedColormap(google_turbo_data[50:])\n",
    "# cmap.set_over('black')\n",
    "cmap = plt.cm.viridis_r\n",
    "norm = BoundaryNorm(rps[rps>=1], cmap.N)\n",
    "\n",
    "mmap = {\n",
    "    'Hsurge': '^',\n",
    "    'Hskewsurge': '^',\n",
    "    'Q': 's',\n",
    "}\n",
    "cmmap = {\n",
    "    'Hsurge': plt.cm.tab10.colors[0],\n",
    "    'Hskewsurge': plt.cm.tab10.colors[0],\n",
    "    'Q': plt.cm.tab10.colors[2],\n",
    "}\n",
    "labs = {\n",
    "    'Hsurge': '$H_{surge}$',\n",
    "    'Hskewsurge': '$H_{SS}$',\n",
    "    'Q': 'Q',\n",
    "}\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "xlim = [0.1,40]\n",
    "shape=(2,len(locs))\n",
    "fig = plt.figure(figsize=(len(locs)*4, 8.5))\n",
    "grid = plt.GridSpec(*shape, hspace=0.15, wspace=0.15)\n",
    "\n",
    "kwargs = dict(cmap=cmap, norm=norm, linewidth=0.5, edgecolor='k', s=35)\n",
    "\n",
    "for i, loc in enumerate(locs):\n",
    "    name = riv_names.get(loc,'unknown')\n",
    "    gdf_loc = gdf.loc[loc,:]    \n",
    "    irow = i // shape[1]\n",
    "    icol = i % shape[1]\n",
    "    \n",
    "    # get data\n",
    "    ts_loc = ds.sel(index=loc, ensemble=model2).reset_coords(drop=True)\n",
    "    df_loc = ds_peaks.sel(index=loc, ensemble=model2).reset_coords(drop=True).to_dataframe()\n",
    "#     df_loc[~np.isfinite(df_loc)] = 0.9\n",
    "\n",
    "    # plot rp\n",
    "    ax = fig.add_subplot(grid[irow, icol])\n",
    "    c = weibull(df_loc['h'].values)\n",
    "    ythresh = np.percentile(ts_loc[drivers[0]], 75)\n",
    "    xthresh = np.percentile(ts_loc[drivers[1]], 75)\n",
    "    ypeaks = get_peaks(ts_loc[drivers[0]], min_dist=30)\n",
    "    ypeaks = ypeaks.where(ypeaks>ythresh).dropna('time').values #.groupby('time.year').max('time').values\n",
    "    xpeaks = get_peaks(ts_loc[drivers[1]], min_dist=45)\n",
    "    xpeaks = xpeaks.where(xpeaks>xthresh).dropna('time').values #.groupby('time.year').max('time').values\n",
    "    xx = np.maximum(rps[0]*1.1,_interp_ev(xpeaks, df_loc[f'{drivers[1]}'].values, 35))\n",
    "    yy = np.maximum(rps[0]*1.1,_interp_ev(ypeaks, df_loc[f'{drivers[0]}'].values, 35))\n",
    "    im = ax.scatter(x=xx, y=yy, c=c, **kwargs)\n",
    "    \n",
    "    # plot rank correlation\n",
    "    ax1 = fig.add_subplot(grid[irow+1, icol])\n",
    "    for v in drivers:\n",
    "        ax1.plot(rankdata(df_loc[v]), rankdata(df_loc['h']), color=cmmap[v], label=labs[v], marker=mmap[v], \n",
    "                 linewidth=0, markeredgewidth=0.7, markeredgecolor='grey', markersize=5 if mmap[v]=='s' else 6)\n",
    "    ax1.plot([0, 41],[0, 41],'--k',zorder=-1)\n",
    "    \n",
    "    # labels\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    if i == 0:\n",
    "        ax.set_yticks(rps)\n",
    "        ax.set_yticklabels(rps)\n",
    "        ax.set_ylabel(labs[drivers[0]]+' return period [years]')\n",
    "        ax1.set_ylabel('riverine water level rank [-]')\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax1.set_yticklabels([])\n",
    "        ax1.set_ylabel(\"\")\n",
    "    ax.set_xticks(rps)\n",
    "    ax.set_xticklabels(rps)\n",
    "    ax.set_xlabel(labs[drivers[1]]+' return period [years]')\n",
    "    ax1.set_xlabel('driver rank [-]')\n",
    "    ax.set_title(f'{letters[i]}. {name} River')\n",
    "    \n",
    "    # axis\n",
    "    ax.set_xlim([rps[0], 38])\n",
    "    ax.set_ylim([rps[0], 38])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(False)\n",
    "    ax1.set_xlim([0.5, 41])\n",
    "    ax1.set_ylim([0.5, 41])\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.grid(False)\n",
    "    \n",
    "    # text \n",
    "    Hr = float(ds_spear.sel(index=loc, ensemble=model2)[f'{drivers[0]}_r'].values)\n",
    "    Qr = float(ds_spear.sel(index=loc, ensemble=model2)[f'{drivers[1]}_r'].values)\n",
    "    Hp = float(ds_spear.sel(index=loc, ensemble=model2)[f'{drivers[0]}_p'].values)\n",
    "    Qp = float(ds_spear.sel(index=loc, ensemble=model2)[f'{drivers[1]}_p'].values)\n",
    "    ax1.text(1, 35.5, labs[drivers[0]]+f': {Hr:.2f} ({Hp:.2f})\\n{labs[drivers[1]]}: {Qr:.2f} ({Qp:.2f})')\n",
    "\n",
    "    # make colorbar\n",
    "pad, shrink, fraction = 0.02, 1.0, 0.04\n",
    "cax = fig.add_axes([1, 1, 0.1, 0.1]) # new ax\n",
    "cbar = fig.colorbar(im, extend='max', cax=cax)\n",
    "cbar.ax.set_ylabel(\"riverine water level\\n return period [years]\", rotation='vertical')\n",
    "posn = ax.get_position()\n",
    "cax.set_position([posn.x1+pad, posn.y0+posn.height*(1-shrink)/2., posn.width*fraction, posn.height*shrink])\n",
    "\n",
    "ax1.legend(loc='lower left', bbox_to_anchor=(1.05, 0.5), title='driver')\n",
    "\n",
    "posn = ax1.get_position()\n",
    "axg = fig.add_axes([posn.x1+0.01, posn.y0-0.1, posn.width*0.8, posn.height], projection=crs_sub) # new ax   \n",
    "basemap(axg, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, features=['land'])\n",
    "gdf.loc[locs,:].plot(ax=axg, marker='o', color='red', markersize=50, legend=True)\n",
    "for i, loc in enumerate(locs):\n",
    "    x, y = gdf.loc[loc,:].geometry.coords[0]\n",
    "    axg.text(x+10, y, letters[i], transform=crs_sub)\n",
    "\n",
    "fn_fig = join(fdir, f'locs_rp_spearmanr_{drivers[0]}_{model2}_wdw{wdw}.png')\n",
    "print(basename(fn_fig))\n",
    "plt.savefig(fn_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "rm = {'Hskewsurge_day':'Hskewsurge', 'Htot_day_max': 'Htot', 'Htide_day_max': 'Htide', 'Hsurge_day_max': 'Hsurge'}\n",
    "ds = xr.open_zarr(fn_rivmth_ts).sel(scen='surge').drop(['Hsurge', 'Htide']).rename(rm)\n",
    "# ds1 = ds.sel(time=slice('01-09-2003', '31-10-2003'))\n",
    "rps = np.array([0.25, 0.5, 1, 2, 4, 8, 16, 32])\n",
    "cmap = plt.cm.viridis_r\n",
    "norm = BoundaryNorm(rps[rps>=1], cmap.N)\n",
    "kwargs = dict(cmap=cmap, norm=norm, linewidth=0.5, edgecolor='k', s=35)\n",
    "# for loc in gdf[gdf['driver']==1].sort_values(by='Q_mean').tail(10).index.tolist() +\\\n",
    "#             gdf[gdf['driver']==2].sort_values(by='Q_mean').tail(10).index.tolist() +\\\n",
    "#             gdf[gdf['driver']==3].sort_values(by='Q_mean').tail(10).index.tolist() +\\\n",
    "#             gdf[gdf['driver']==4].sort_values(by='Q_mean').tail(10).index.tolist():\n",
    "for loc in locs:\n",
    "\n",
    "    plt.close('all')\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    grid = plt.GridSpec(6,5, hspace=0.15, wspace=0.25)\n",
    "\n",
    "    name = riv_names.get(loc,'unknown')\n",
    "    gdf_loc = gdf.loc[loc,:]    \n",
    "    \n",
    "    # get data\n",
    "    ts_loc = ds.sel(index=loc, ensemble=model2).reset_coords(drop=True)\n",
    "    t = ts_loc.time.values\n",
    "    tlim = t[ts_loc.time.dt.year==2000][0], t[-1]\n",
    "    df_loc = ds_peaks.sel(index=loc, ensemble=model2).reset_coords(drop=True).to_dataframe()\n",
    "    tam = pd.to_datetime([f'{yr:04d}{doy:02.0f}' for yr,doy in zip(df_loc.index, df_loc.dayofyear)], format = \"%Y%j\")\n",
    "    Hthresh = np.percentile(ts_loc[drivers[0]], 75)\n",
    "    Hpeaks = get_peaks(ts_loc[drivers[0]], min_dist=30).reindex(time=t)\n",
    "    Hpeaks = Hpeaks.where(Hpeaks>Hthresh)\n",
    "    Qthresh = np.percentile(ts_loc[drivers[1]], 75)\n",
    "    Qpeaks = get_peaks(ts_loc[drivers[1]], min_dist=45).reindex(time=t) #.groupby('time.year').max('time').values\n",
    "    Qpeaks = Qpeaks.where(Qpeaks>Qthresh)\n",
    "#     Tthresh = np.percentile(ts_loc['Htot'], 75)\n",
    "#     Tpeaks = get_peaks(ts_loc['Htot'], min_dist=45).reindex(time=t) #.groupby('time.year').max('time').values\n",
    "#     Tpeaks = Tpeaks.where(Tpeaks>Tthresh)\n",
    "    \n",
    "    #plot ts\n",
    "    ax0 = fig.add_subplot(grid[:2, :-1])\n",
    "    ax0.plot(t, ts_loc['WSE'].values, color=plt.cm.tab10.colors[2])\n",
    "    ax0.plot(tam, ts_loc['WSE'].to_series().loc[tam], '.k')\n",
    "    ymin, ymax = ax0.get_ylim()\n",
    "    ax0.vlines(x=tam, ymin=ymin, ymax=ymax, zorder=-1, color='k', linewidth=1, linestyle='-')\n",
    "    ax0.set_xticklabels([])\n",
    "    ax0.set_xlim(tlim)\n",
    "    ax0.set_ylim([ymin, ymax])\n",
    "    ax0.set_ylabel('WSE')\n",
    "    \n",
    "    ax0 = fig.add_subplot(grid[2:4, :-1])\n",
    "    ax0.plot(t, ts_loc['Q'].values, color=cmmap['Q'])\n",
    "    ax0.plot(t, Qpeaks.values, '.k')\n",
    "    ymin, ymax = ax0.get_ylim()\n",
    "    ax0.vlines(x=tam, ymin=ymin, ymax=ymax, zorder=-1, color='k', linewidth=1, linestyle='--')\n",
    "    ax0.set_xlim(tlim)\n",
    "    ax0.set_ylim([ymin, ymax])\n",
    "    ax0.set_xticklabels([])\n",
    "    ax0.set_ylabel('Q')\n",
    "\n",
    "    ax0 = fig.add_subplot(grid[4:, :-1])\n",
    "    ax0.plot(t, ts_loc['Hskewsurge'].values, color=cmmap['Hskewsurge'])\n",
    "    ax0.plot(t, ts_loc['Hseas_day_mean'].values, 'k')\n",
    "    ax0.plot(t, Hpeaks.values, '.k')\n",
    "    ax0.set_ylabel('Hsurge')\n",
    "#     ax0.plot(t, ts_loc['Htot'].values, color=cmmap['Hskewsurge'])\n",
    "#     ax0.plot(t, Tpeaks.values, '.k')\n",
    "#     ax0.set_ylabel('Htot')\n",
    "    ymin, ymax = ax0.get_ylim()\n",
    "    ax0.vlines(x=tam, ymin=ymin, ymax=ymax, zorder=-1, color='k', linewidth=1, linestyle='--')\n",
    "    ax0.set_xlim(tlim)\n",
    "    ax0.set_ylim([ymin, ymax])\n",
    "    \n",
    "    # plot rp\n",
    "    ax = fig.add_subplot(grid[:3, -1])\n",
    "    c = weibull(df_loc['h'].values)\n",
    "    xx = np.maximum(rps[0],_interp_ev(Qpeaks.dropna('time').values, df_loc[f'{drivers[1]}'].values, 35))\n",
    "    yy = np.maximum(rps[0],_interp_ev(Hpeaks.dropna('time').values, df_loc[f'{drivers[0]}'].values, 35))\n",
    "    im = ax.scatter(x=xx, y=yy, c=c, **kwargs)\n",
    "\n",
    "    for iyr, yr in enumerate(tam.year[c>10]):\n",
    "        if yr < 2000: continue\n",
    "        ax.annotate(str(yr), (xx[tam.year==yr], yy[tam.year==yr]))\n",
    "                    \n",
    "    # plot rank correlation\n",
    "    ax1 = fig.add_subplot(grid[3:, -1])\n",
    "    for v in drivers:\n",
    "        ax1.plot(rankdata(df_loc[v]), rankdata(df_loc['h']), color=cmmap[v], label=labs[v], marker=mmap[v], linewidth=0)\n",
    "    ax1.plot([0, 41],[0, 41],'--k')\n",
    "    \n",
    "    # axis\n",
    "    ax.set_xlim([0.85, 38])\n",
    "    ax.set_ylim([0.85, 38])\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(False)\n",
    "    ax1.set_xlim([0.5, 41])\n",
    "    ax1.set_ylim([0.5, 41])\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.grid(False)\n",
    "    \n",
    "    # labels\n",
    "    ax.set_yticks(rps)\n",
    "    ax.set_yticklabels(rps)\n",
    "    ax.set_ylabel(labs[drivers[0]]+' return period [years]')\n",
    "    ax1.set_ylabel('riverine water level rank [-]')\n",
    "    ax.set_xticks(rps)\n",
    "    ax.set_xticklabels(rps)\n",
    "    ax.set_xlabel(labs[drivers[1]]+' return period [years]')\n",
    "    ax1.set_xlabel('driver rank [-]')\n",
    "    ax.set_title(f'{loc}. {name} River')\n",
    "    \n",
    "    # text \n",
    "    Hr = float(ds_spear.sel(index=loc, ensemble=model2)[f'{drivers[0]}_r'].values)\n",
    "    Qr = float(ds_spear.sel(index=loc, ensemble=model2)[f'{drivers[1]}_r'].values)\n",
    "    Hp = float(ds_spear.sel(index=loc, ensemble=model2)[f'{drivers[0]}_p'].values)\n",
    "    Qp = float(ds_spear.sel(index=loc, ensemble=model2)[f'{drivers[1]}_p'].values)\n",
    "    ax1.text(1, 35.5, labs[drivers[0]]+f': {Hr:.2f} ({Hp:.2f})\\n{labs[drivers[1]]}: {Qr:.2f} ({Qp:.2f})')\n",
    "       \n",
    "    # make colorbar\n",
    "    pad, shrink, fraction = 0.02, 1.0, 0.04\n",
    "    cax = fig.add_axes([1, 1, 0.1, 0.1]) # new ax\n",
    "    cbar = fig.colorbar(im, extend='max', cax=cax)\n",
    "    cbar.ax.set_ylabel(\"riverine water level\\n return period [years]\", rotation='vertical')\n",
    "    posn = ax.get_position()\n",
    "    cax.set_position([posn.x1+pad, posn.y0+posn.height*(1-shrink)/2., posn.width*fraction, posn.height*shrink])\n",
    "\n",
    "    ax1.legend(loc='lower left', bbox_to_anchor=(1.05, 0.5), title='driver')\n",
    "\n",
    "    posn = ax1.get_position()\n",
    "    axg = fig.add_axes([posn.x1+0.01, posn.y0-0.1, posn.width*0.8, posn.height], projection=crs_sub) # new ax   \n",
    "    basemap(axg, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, features=['land'])\n",
    "    gdf.loc[[loc],:].plot(ax=axg, marker='o', color='red', markersize=25, legend=True)\n",
    "    x, y = gdf.loc[loc,:].geometry.coords[0]\n",
    "    axg.text(x+10, y, loc, transform=crs_sub)\n",
    "\n",
    "#     fn_fig = join(fdir, 'locs', f'loc{loc:04d}_{model2}_wdw{wdw}.png')\n",
    "    fn_fig = join(fdir, f'loc{loc:04d}_{model2}_wdw{wdw}.png')\n",
    "    print(basename(fn_fig))\n",
    "    plt.savefig(fn_fig)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "qmin=0\n",
    "labels = {\n",
    "    'h': '$\\Delta h$ at'+f' T{rp} [m]',\n",
    "    'scale': f'difference in Gumbel scale ($\\\\beta$) parameter',\n",
    "    'loc': f'difference in Gumbel location ($\\mu$) parameter',\n",
    "}\n",
    "vmaxs = {\n",
    "    'h': 1.0, 'loc': 0.6, 'scale': 0.15\n",
    "}\n",
    "vmins = {\n",
    "    'h': -0.1, 'loc': -0.2, 'scale': -0.15\n",
    "}\n",
    "names = {\n",
    "    'loc': '$\\mu$', 'scale': '$\\\\beta$'\n",
    "}\n",
    "diff_names = {\n",
    "    0: '',\n",
    "    1: '$_{daily}$',\n",
    "    2: '$_{seasonal}$',\n",
    "}\n",
    "\n",
    "mp = 0.45\n",
    "plt.close('all')\n",
    "\n",
    "# cmap = ListedColormap(sns.color_palette(\"coolwarm\", 200))\n",
    "# cmap = cmap_turbo_div\n",
    "for par in ['h', 'scale', 'loc'][:1]:\n",
    "    var = f'diff_{par}_surge_tide'\n",
    "    vmin, vmax = vmins[par],  vmaxs[par]\n",
    "    n = vmax/abs(vmin)+2\n",
    "    norm = MidpointNormalize(vmin=vmin, vmax=vmax, midpoint=0.)\n",
    "    cticks=np.linspace(vmin, vmax, n)\n",
    "    cmap = ListedColormap([interpolate_cmap(plt.cm.RdBu_r(np.arange(256)), x) for x in \n",
    "                           np.hstack([np.linspace(mp+mp*4*vmin,mp,100), np.linspace(1-mp,1,100)])])    \n",
    "\n",
    "    if par == 'h':\n",
    "        fn_fig = join(fdir, f'{var}_{model}_T{rp:03d}.png')\n",
    "        label = labels[par].format(rp=rp)\n",
    "    elif irp > 0: \n",
    "        continue\n",
    "    else:\n",
    "        fn_fig = join(fdir, f'{var}_{model}.png')\n",
    "        label = labels[par]\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10.5))\n",
    "    grid = plt.GridSpec(3, 2, wspace=0.04, hspace=0.01)\n",
    "\n",
    "    column = var\n",
    "    gdf0 = gdf[np.logical_or(gdf[f'{var}_sign']==0, gdf['Q_mean']<qmin)].copy()\n",
    "    gdf1 = gdf[np.logical_and(np.logical_and(gdf[f'{var}_sign']==1, gdf[f'{var}_sign_ci']!=1), gdf['Q_mean']>=qmin)].copy().sort_values(column, ascending=True)\n",
    "    gdf2 = gdf[np.logical_and(np.logical_and(gdf[f'{var}_sign']==1, gdf[f'{var}_sign_ci']==1), gdf['Q_mean']>=qmin)].copy().sort_values(column, ascending=True)\n",
    "\n",
    "    # main map\n",
    "    axg = fig.add_subplot(grid[:-1, :], projection=crs_sub)\n",
    "    basemap(axg, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, **bmap_kwargs)\n",
    "    gdf0.plot(ax=axg, marker='x', color=(0, 0, 0, 0.6), markersize=15, linewidth=0.2, alpha=0.6, legend=False)\n",
    "    plot_kwargs.update(markersize=25, marker='o', linewidth=0.5)\n",
    "    plot_choropleth(\n",
    "        fig, axg, gdf1, column=column, \n",
    "        cmap=cmap, vmin=vmin, vmax=vmax, cticks=cticks, norm=norm, discrete=False, \n",
    "        plot_kwargs=plot_kwargs,\n",
    "        cbar_kwargs=dict(label=label, location='right', extend='both'),\n",
    "        cbar_pos = dict(pad=0.02, fraction=0.01, shrink=0.6)\n",
    "    )\n",
    "    if len(gdf2) > 0:\n",
    "        plot_kwargs.update(markersize=25, marker='d', linewidth=0.5)\n",
    "        cax = plot_choropleth(\n",
    "            fig, axg, gdf2, column=column, \n",
    "            cmap=cmap, vmin=vmin, vmax=vmax, cticks=cticks, norm=norm, discrete=False, \n",
    "            plot_kwargs=plot_kwargs,\n",
    "\n",
    "        )\n",
    "    axg.text(-175, 85, letters[0]+'. $\\Delta$'+names.get(par,par)+diff_names[0], transform=crs_sub, fontsize='large')\n",
    "\n",
    "    for i, var in enumerate([f'diff_{par}_surge_seas', f'diff_{par}_seas_tide']):\n",
    "\n",
    "        column = var\n",
    "        gdf0 = gdf[np.logical_or(gdf[f'{var}_sign']==0, gdf['Q_mean']<qmin)].copy()\n",
    "        gdf1 = gdf[np.logical_and(np.logical_and(gdf[f'{var}_sign']==1, gdf[f'{var}_sign_ci']!=1), gdf['Q_mean']>=qmin)].copy().sort_values(column, ascending=True)\n",
    "        gdf2 = gdf[np.logical_and(np.logical_and(gdf[f'{var}_sign']==1, gdf[f'{var}_sign_ci']==1), gdf['Q_mean']>=qmin)].copy().sort_values(column, ascending=True)\n",
    "\n",
    "        # main map\n",
    "        axg = fig.add_subplot(grid[-1, i], projection=crs_sub)\n",
    "        basemap(axg, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, **bmap_kwargs)\n",
    "        gdf0.plot(ax=axg, marker='x', color=(0, 0, 0, 0.6), markersize=10, linewidth=0.2, alpha=0.6, legend=False)\n",
    "\n",
    "        plot_kwargs.update(markersize=20, marker='o', linewidth=0.5)\n",
    "        cax = plot_choropleth(\n",
    "            fig, axg, gdf1, column=column, \n",
    "            cmap=cmap, vmin=vmin, vmax=vmax, cticks=cticks, norm=norm, discrete=False, \n",
    "            plot_kwargs=plot_kwargs,\n",
    "        )\n",
    "        if len(gdf2) > 0:\n",
    "            plot_kwargs.update(markersize=s, marker='d')\n",
    "            cax = plot_choropleth(\n",
    "                fig, axg, gdf2, column=column, \n",
    "                cmap=cmap, vmin=vmin, vmax=vmax, cticks=cticks, norm=norm, discrete=False, \n",
    "                plot_kwargs=plot_kwargs\n",
    "            )\n",
    "        axg.text(-175, 85, letters[i+1]+'. $\\Delta$'+names.get(par,par)+diff_names[i+1], transform=crs_sub, fontsize='large')\n",
    "\n",
    "    print(basename(fn_fig))\n",
    "    plt.savefig(fn_fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "basins = gpd.read_file(r'/home/dirk/models/cama-flood_bmi_v3.6.2/map/global_15min/flw_basins')\n",
    "basins['area'] = basins.area\n",
    "basins['rivmth_idx'] = basins['DN'] - 1\n",
    "# basins = basins.sort_values(by='area',ascending=False).drop_duplicates(subset='rivmth_idx')\n",
    "basins = basins.merge(gdf.drop(columns='geometry'), on='rivmth_idx', how='right')\n",
    "# fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "# basins.plot(linewidth=0.1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmin=0\n",
    "\n",
    "column = f'people_affected_dH_dp'\n",
    "label=f'people affected [-]'\n",
    "vmin, vmax, n= 2, 6, 5\n",
    "cticks=np.linspace(vmin, vmax, n)\n",
    "cmap = ListedColormap(sns.cubehelix_palette(16, start=.5, rot=-.75))\n",
    "\n",
    "# var = f'diff_h_surge_tide'\n",
    "# gdf0 = basins[np.logical_or(basins[f'{var}_sign']==0, basins['Q_mean']<qmin)].copy()\n",
    "# gdf1 = basins[np.logical_and(basins[f'{var}_sign']==1, basins['Q_mean']>=qmin)].copy().sort_values(column, ascending=False)\n",
    "gdf1 = basins.copy()\n",
    "if 'perc' not in column:\n",
    "    gdf1[column] = np.where(gdf1[column]<=0, 0, np.log10(gdf1[column]))\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(18, 10.5))\n",
    "grid = plt.GridSpec(2, 1, wspace=0.01, hspace=0.01)\n",
    "\n",
    "# map 1\n",
    "axg = fig.add_subplot(grid[0, 0], projection=crs_sub)\n",
    "basemap(axg, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, features=['land'], **bmap_kwargs)\n",
    "plot_kwargs.pop('marker',None)\n",
    "plot_kwargs.pop('markersize',None)\n",
    "plot_kwargs.update(linewidth=0.1)\n",
    "cax = plot_choropleth(\n",
    "    fig, axg, gdf1, column=column, \n",
    "    cmap=plt.cm.Greens , cticks=cticks, vmin=vmin, vmax=vmax, discrete=False, \n",
    "    plot_kwargs = plot_kwargs,\n",
    "    cbar_kwargs = dict(label=label, location='right'),\n",
    "    cbar_pos = dict(pad=0.02, fraction=0.01, shrink=0.5)\n",
    ")\n",
    "cax.set_yticklabels([f'$10^{e:0.0f}$' for e in cticks])\n",
    "axg.text(-175, 85, letters[0]+'', transform=crs_sub, fontsize='large')\n",
    "    \n",
    "column = f'people_affected_dH_dp_perc'\n",
    "label=f'people affected [%]'\n",
    "vmin, vmax, n= 0, 40, 5\n",
    "cticks=np.linspace(vmin, vmax, n)\n",
    "# cmap = ListedColormap(sns.cubehelix_palette(16, start=.5, rot=-.75))\n",
    "\n",
    "# map 2\n",
    "axg2 = fig.add_subplot(grid[1, 0], projection=crs_sub)\n",
    "basemap(axg2, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, features=['land'], **bmap_kwargs)\n",
    "plot_kwargs.pop('marker',None)\n",
    "plot_kwargs.pop('markersize',None)\n",
    "plot_kwargs.update(linewidth=0.1)\n",
    "cax2 = plot_choropleth(\n",
    "    fig, axg2, gdf1, column=column, \n",
    "    cmap=plt.cm.Blues, cticks=cticks, vmin=vmin, vmax=vmax, discrete=False, \n",
    "    plot_kwargs = plot_kwargs,\n",
    "    cbar_kwargs = dict(label=label, location='right'),\n",
    "    cbar_pos = dict(pad=0.02, fraction=0.01, shrink=0.5)\n",
    ") \n",
    "axg2.text(-175, 85, letters[1], transform=crs_sub, fontsize='large')\n",
    "\n",
    "\n",
    "fn_fig = join(fdir, f'expected_annual_people_exposed_{model}.png')\n",
    "print(basename(fn_fig))\n",
    "plt.savefig(fn_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clist = plt.cm.tab10.colors\n",
    "mmapp = {\n",
    "#     'compound_(N=5)': 'd', \n",
    "    'insign': 'o',\n",
    "    'compound': 'd',\n",
    "    'H': '^', \n",
    "    'Q': 's', \n",
    "}\n",
    "cmapp = {'compound_(N=5)': clist[3], f'compound': clist[1],\n",
    "         'H': clist[0], 'Q': clist[2], 'insign': 'grey'}\n",
    "nmapp = {\n",
    "    'H': {'Hsurge': 'Surge', 'Hskewsurge': 'Skew Surge'}[drivers[0]], \n",
    "    'Q': 'Discharge',\n",
    "    'insign': 'Insignificant',\n",
    "    'compound': 'Compound',\n",
    "    'all': 'All locations'\n",
    "}\n",
    "\n",
    "\n",
    "label=f'spearman correlation [-]'\n",
    "s=20\n",
    "vmin, vmax, n= 0.5, 1, 6\n",
    "cticks=np.linspace(vmin, vmax, n)\n",
    "cmap  = plt.cm.Blues\n",
    "\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(18, 10.5))\n",
    "grid = plt.GridSpec(3, 2, wspace=0.02, hspace=0.01)\n",
    "        \n",
    "# main map\n",
    "var = f'diff_h_surge_tide'\n",
    "# gdf0 = gdf[gdf[f'{var}_sign']==0]\n",
    "gdf1 = gdf#[gdf[f'{var}_sign']==1].copy().sort_values(var, ascending=True)\n",
    "       \n",
    "axg = fig.add_subplot(grid[:-1, :], projection=crs_sub)\n",
    "basemap(axg, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, **bmap_kwargs)\n",
    "# gdf0.plot(ax=axg, marker='x', color=(0, 0, 0, 0.6), markersize=12, linewidth=0.2, alpha=0.6, label='insignificant $\\Delta h$')\n",
    "for d in list(mmapp.keys())[::-1]:\n",
    "    if f'driver_{d}' not in gdf1.columns: continue\n",
    "    gdf1[gdf1[f'driver_{d}']==True].plot(\n",
    "        ax=axg, marker=mmapp[d], color=cmapp[d], \n",
    "        markersize=s, linewidth=0.5, legend=False, \n",
    "#         label=' '.join(d.split('_')).replace('H','$H_{surge}$').replace('insign', 'no classification')\n",
    "        label = nmapp.get(d, d)\n",
    "    )\n",
    "axg.legend(loc='lower left', bbox_to_anchor=(0.05, 0.1))\n",
    "axg.text(-175, 85, f'{letters[0]}. Flood driver classification', transform=crs_sub, fontsize='large')\n",
    "\n",
    "for i, v in enumerate(['H', 'Q']):\n",
    "    # main map\n",
    "    axg = fig.add_subplot(grid[-1, i], projection=crs_sub)\n",
    "    basemap(axg, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, **bmap_kwargs)\n",
    "    column = f'driver_{v}_r'\n",
    "    gdf0 = gdf[gdf[f'driver_{v}_sign']==False]\n",
    "    gdf1 = gdf[gdf[f'driver_{v}_sign']==True].sort_values(by=column, ascending=True)\n",
    "    gdf0.plot(ax=axg, marker='x', color=(0, 0, 0, 0.6), markersize=12, linewidth=0.2, alpha=0.6, legend=False)\n",
    "    plot_kwargs.update(markersize=12)\n",
    "    cax = plot_choropleth(\n",
    "        fig, axg, gdf1, column=column, \n",
    "        cmap=cmap, vmin=vmin, vmax=vmax, cticks=cticks, discrete=False,\n",
    "        plot_kwargs=plot_kwargs,\n",
    "        cbar_kwargs=dict(label=label, location='right', extend='min') if i == 1 else None,\n",
    "        cbar_pos = dict(pad=0.02, fraction=0.015, shrink=0.8) \n",
    "    )\n",
    "    axg.text(-175, 85, f'{letters[i+1]}. {nmapp[v]}', transform=crs_sub, fontsize='large')\n",
    "fn_fig = join(fdir, f'spearman_driver_{drivers[0]}_wdw{wdw}_{model}.png')\n",
    "print(basename(fn_fig))\n",
    "plt.savefig(fn_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vvs = {\n",
    "    'drivers': {\n",
    "#         'Hseasrange_cm': dict(label='seasonal sea level range [cm]'),\n",
    "        'Hskewsurge_amax_cm': dict(label='mean annual max. skew surge [cm]'),\n",
    "#         'Hskewsurge_amax_cv': dict(label='interannual variability (CV)\\nannual max. skew surge [-]', fmt='.2f'),\n",
    "\n",
    "        'Q_amax': dict(label='mean annual max. discharge [m$^3$ s$^{-1}$]'),\n",
    "    },\n",
    "    'basin': {\n",
    "        'Q_mean': dict(label='mean discharge [m$^3$ s$^{-1}$]'),\n",
    "        'Q_amax_cv': dict(label='interannual variability (CV)\\nannual max. discharge [-]', fmt='.2f'),\n",
    "        'uparea_100': dict(label='catchment area [x100 km$^2$]'),\n",
    "#         'mean_drain_length': dict(label='mean drainage length [km]'),\n",
    "        'mean_drain_slope': dict(label='mean drainage slope [m km$^{-1}$]', fmt='.2f'),\n",
    "    }\n",
    "}\n",
    "rp=10\n",
    "dh=0.12\n",
    "var = f'diff_h_surge_tide'\n",
    "attrs_sign = gdf[gdf[f'{var}_sign']==1]\n",
    "# attrs_sign = attrs2[attrs2['Hseasrange_cm']>13]\n",
    "\n",
    "box_kwargs=dict(whis=[5,95], boxprops=dict(linewidth=1.), medianprops=dict(linewidth=1.5), \n",
    "                showfliers=False, flierprops=dict(markersize=2))\n",
    "\n",
    "for kind, vs in vvs.items(): \n",
    "    fig = plt.figure(figsize=(len(vs)*4, 3.5))\n",
    "    grid = plt.GridSpec(1, len(vs.keys()), hspace=0.1, wspace=0.1)\n",
    "    ylim2 = [-0.1, 1.1]\n",
    "    ylab2 = f'difference in riverine water level [m]\\n 1-in-{rp} years return period'\n",
    "    ylab1 = 'count [-]'\n",
    "    for i, name in enumerate(vs):\n",
    "\n",
    "        ax2 = fig.add_subplot(grid[:,i])\n",
    "\n",
    "        qbins = np.arange(0,0.99,0.25)\n",
    "        bins = attrs_sign[name].quantile(qbins).values\n",
    "#         print(name, bins)\n",
    "        n = len(bins)\n",
    "        lab = vs[name]['label']\n",
    "        fmt = vs[name].get('fmt', None)\n",
    "        if fmt == '.2f':\n",
    "            ticklabs = [f'{v0:.2f}' for v0 in  bins]\n",
    "        elif fmt == '.1f':\n",
    "            ticklabs = [f'{v0:.1f}' for v0 in  bins]\n",
    "        else:\n",
    "            ticklabs = [f'{v0:.0f}' for v0 in  bins]\n",
    "        for ii, v in enumerate(['Q', 'H', f'compound', 'all']):\n",
    "            if v != 'all':\n",
    "                df = attrs_sign[attrs_sign[f'driver_{v}']==1].copy()\n",
    "            else:\n",
    "                df = attrs_sign.copy()\n",
    "#             bins = df[name].quantile(qbins).values\n",
    "    #         positions=np.arange(n)+(-1 if ii==0 else 1)*dh*0.75\n",
    "#             positions=np.arange(n)+(ii-1)*dh*1.5\n",
    "            positions=np.arange(n)+0.5*dh+(ii-2)*dh*1.5\n",
    "            df['bins'] = np.digitize(df[name],bins)\n",
    "            dd = df.boxplot(column=var, by='bins', widths=dh, positions=positions, ax=ax2, return_type='dict', **box_kwargs)\n",
    "            # plot lines for legend\n",
    "            if i == len(vs)-1:\n",
    "                ax2.plot([0,1],[2,2], color=cmapp.get(v, 'k'), label=v.split('_')[0].replace('H','$H_{surge}$'))\n",
    "            for _, row in dd.iteritems():\n",
    "                c = cmapp.get(v, 'k')\n",
    "                for box in row['boxes']:\n",
    "                    box.set_color(c)\n",
    "                for med in row['medians']:\n",
    "                    med.set_color(c)\n",
    "                for w in row['whiskers']:\n",
    "                    w.set_color(c)\n",
    "                for cap in row['caps']:\n",
    "                    cap.set_color(c)\n",
    "    #     positions=np.arange(n)\n",
    "    #     df = attrs_sign.copy()\n",
    "    #     df['bins'] = np.digitize(df[name],bins)\n",
    "    #     dd = df.boxplot(column=var, by='bins', ax=ax2, positions=positions, **box_kwargs)\n",
    "\n",
    "        ax2.set_ylim(ylim2)\n",
    "        ax2.set_xlim([-0.5,n-0.5])\n",
    "        ax2.set_xticks(np.arange(n)-0.5)\n",
    "        ax2.set_xticklabels(ticklabs)\n",
    "        ax2.set_xlabel(lab)\n",
    "        ax2.set_title('')\n",
    "        ax2.text(-0.4,1.02, letters[i])\n",
    "#         ax2.xaxis.grid(False)\n",
    "\n",
    "        if i != 0:\n",
    "            ax2.set_yticklabels([])\n",
    "        else:\n",
    "            ax2.set_ylabel(ylab2)\n",
    "\n",
    "    ax2.legend(loc='lower left', bbox_to_anchor=(1.05, 0.5), title='main driver')\n",
    "    fig.suptitle('')\n",
    "\n",
    "    fn = join(fdir, f'boxplot_{var}_rp{rp:03d}_vs_{kind}_{drivers[0]}_{model}.png')\n",
    "    print(basename(fn))\n",
    "    plt.savefig(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = {\n",
    "#     'Hseasrange': dict(label='seasonal sea level range [m]', ylim=[0, 0.5]),\n",
    "    'Hskewsurge_amax': dict(label='$H_{SS}$ [m]', ylim=[0,1.5], title='Mean annual max. $H_{SS}$\\n'),\n",
    "    'Hskewsurge_amax_cv': dict(label='Coef. of variation  [-]', fmt='.2f', ylim=[0,0.6], title='Coef. of variation \\nannual max. $H_{SS}$'),\n",
    "    'Q_amax_log10': dict(label='Q [m$^3$ s$^{-1}$]', fmt='e', ylim=[0.5,4.0], title='Mean annual max. $Q$\\n'),\n",
    "    'Q_amax_cv': dict(label='Coef. of variation [-]', ylim=[0,1.5], title='Coef. of variation \\nannual max. $Q$'),\n",
    "\n",
    "    'Q_mean_log10': dict(label='Q [m$^3$ s$^{-1}$]', fmt='e', ylim=[0,3.2], title='Long term mean $Q$'),\n",
    "#     'runoff': dict(label='mean runoff [mm]'),\n",
    "    'uparea_log10': dict(label='Area [km$^2$]', fmt='e', ylim=[3,5], title='Catchment area'),\n",
    "    'mean_drain_length': dict(label='Length [km]', ylim=[0,400], title='Drainage length'),\n",
    "    'mean_drain_slope': dict(label='Slope [m km$^{-1}$]', fmt='.2f', ylim=[0,8], title='Drainage slope'),\n",
    "}\n",
    "\n",
    "box_kwargs=dict(whis=[5,95], boxprops=dict(linewidth=1.), medianprops=dict(linewidth=1.5), \n",
    "                showfliers=False, flierprops=dict(markersize=2), showmeans=True, meanprops=dict(marker='s', markersize=5))\n",
    "\n",
    "gdf['Q_amax_log10'] = np.log10(np.maximum(1, gdf['Q_amax']))\n",
    "gdf['Q_mean_log10'] = np.log10(np.maximum(1, gdf['Q_mean']))\n",
    "gdf['uparea_log10'] = np.log10(np.maximum(1, gdf['uparea']))\n",
    "gdf['runoff'] = gdf['Q_mean'] / (gdf['uparea']*1e6) * 1e3 #[mm]\n",
    "gdf['driver'] = gdf['driver_H']+gdf['driver_Q']*2+gdf[f'driver_compound']*3\n",
    "\n",
    "\n",
    "dh=0.12\n",
    "var = f'diff_h_surge_tide'\n",
    "df1 = gdf  #[gdf[f'{var}_sign']==1].drop(columns=['geometry'])\n",
    "\n",
    "\n",
    "ncol = int(np.ceil(len(vs)/2))\n",
    "fig = plt.figure(figsize=(ncol*2.5, 2*3))\n",
    "grid = plt.GridSpec(2, ncol, hspace=0.2, wspace=0.55)\n",
    "\n",
    "for i, name in enumerate(vs):\n",
    "    irow = int(i // ncol)\n",
    "    icol = int(i % ncol)\n",
    "    ax2 = fig.add_subplot(grid[irow, icol])\n",
    "    \n",
    "    samples = {v: df1[[name]][df1[f'driver_{v}']==1] for v in ['Q', 'H', 'compound']}\n",
    "    samples['all'] = df1[[name]]\n",
    "#     print({n: f'{float(df.var()):.2f}' for n,df in samples.items()})\n",
    "    \n",
    "    for ii, v in enumerate(['all','Q', 'H', 'compound']):\n",
    "        sign = True\n",
    "        if v != 'all':\n",
    "            other = [v1 for v1 in ['Q', 'H', 'compound'] if v1 != v]\n",
    "            sign = np.all(np.array([float(ttest_ind(samples[v], samples[v1], equal_var=True)[1]) for v1 in other])<0.01)\n",
    "        positions=[0.5*dh+(ii-2)*dh*1.5]       \n",
    "        dd = samples[v].boxplot(column=name, widths=dh, positions=positions, ax=ax2, return_type='dict', **box_kwargs)\n",
    "        # plot lines for legend\n",
    "        if i == len(vs)-1:\n",
    "            ax2.plot([2,2],[0,2], color=cmapp.get(v, 'k'), label=nmapp.get(v,v))\n",
    "        c = cmapp.get(v, 'k')\n",
    "        for box in dd['boxes']:\n",
    "            box.set_color(c)\n",
    "        for med in dd['medians']:\n",
    "            med.set_color(c)\n",
    "        for w in dd['whiskers']:\n",
    "            w.set_color(c)\n",
    "        for cap in dd['caps']:\n",
    "            cap.set_color(c)\n",
    "        for p in dd['means']:\n",
    "            if v == 'all':\n",
    "                p.set_marker('x')\n",
    "            if sign:\n",
    "                p.set_markerfacecolor(c)\n",
    "            else:\n",
    "                p.set_markerfacecolor('none')\n",
    "            p.set_markeredgecolor(c)\n",
    "\n",
    "#     ax2.plot([2],[0], marker='s', markerfacecolor='k', label='mean', linewidth=0, markeredgecolor='k' )\n",
    "    ylim = vs[name].get('ylim', None)\n",
    "    if ylim is not None:\n",
    "        ymin, ymax = ylim\n",
    "    else:\n",
    "        ymin, ymax = samples['all'][name].quantile([0.00,0.99])\n",
    "        \n",
    "    fmt = vs[name].get('fmt', None)\n",
    "    if fmt == 'e':\n",
    "        yticks = np.arange(np.floor(ymin), np.ceil(ymax), 1)\n",
    "        yticklabels = [f'10$^{t:.0f}$' for t in yticks]\n",
    "        ax2.set_yticks(yticks)\n",
    "        ax2.set_yticklabels(yticklabels)\n",
    "    \n",
    "    lab = vs[name]['label']\n",
    "    title = vs[name].get('title', name)\n",
    "    ax2.set_ylabel(lab)\n",
    "    ax2.set_xlim([-0.45,0.4])\n",
    "    ax2.set_ylim([ymin, ymax])\n",
    "    ax2.set_xticks([])\n",
    "    ax2.set_title(f'{letters[i]}. {title}')\n",
    "#     ax2.text(0.05,0.93, letters[i], transform=ax2.transAxes)\n",
    "\n",
    "ax2.legend(loc='lower left', bbox_to_anchor=(1.05, 0.5), title='main driver')\n",
    "# fig.suptitle('')\n",
    "\n",
    "fn = join(fdir, f'boxplot_classification_{model}.png')\n",
    "print(basename(fn))\n",
    "plt.savefig(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
