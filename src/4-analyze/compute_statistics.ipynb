{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from os.path import join, isfile\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../3-postprocess/'))\n",
    "from xstats import xrankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = r'/scratch/compound_hotspots'\n",
    "ddir = join(root, 'data', '4-postprocessed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compound EV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_ev = join(ddir, 'rivmth_AMpeaks_d14_ev_gumb.nc')\n",
    "fn_ev_out = join(ddir, 'rivmth_AMpeaks_d14_ev_gumb_stats.nc')\n",
    "\n",
    "ds_ev = xr.open_dataset(fn_ev)\n",
    "\n",
    "da_wse_ev = ds_ev['WSE_ev']#.sel(ensemble='cnrs')\n",
    "diff_cmpnd_surge = (da_wse_ev.sel(scen='cmpnd') - da_wse_ev.sel(scen='surge'))\n",
    "diff_cmpnd_surge.name = 'diff_surge'\n",
    "diff_cmpnd_runoff = (da_wse_ev.sel(scen='cmpnd') - da_wse_ev.sel(scen='runoff'))\n",
    "diff_cmpnd_runoff.name = 'diff_runoff'\n",
    "\n",
    "runoff_is_main_driver = da_wse_ev.sel(scen='runoff') >= da_wse_ev.sel(scen='surge')\n",
    "runoff_is_main_driver.name = 'runoff'\n",
    "surge_is_main_driver = da_wse_ev.sel(scen='runoff') < da_wse_ev.sel(scen='surge')\n",
    "surge_is_main_driver.name = 'surge'\n",
    "\n",
    "compound_positive = np.logical_and(diff_cmpnd_surge>0, diff_cmpnd_runoff>0)\n",
    "compound_positive.name = 'compound'\n",
    "\n",
    "ds_cmpnd = xr.merge([\n",
    "    diff_cmpnd_runoff,\n",
    "    diff_cmpnd_surge,\n",
    "    runoff_is_main_driver,\n",
    "    surge_is_main_driver,\n",
    "    compound_positive,\n",
    "])\n",
    "\n",
    "ds_cmpnd.to_netcdf(fn_ev_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 95\n",
    "min_dist = 30\n",
    "Npeaks = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## top 50 peaks accross scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_peaks_all = join(ddir, f'rivmth_peaks_q{q}d{min_dist}_top{Npeaks}_all.nc')\n",
    "ds_peaks_all = xr.open_dataset(fn_peaks_all)\n",
    "\n",
    "# frequency\n",
    "fn_peaks_all_freq = join(ddir, f'rivmth_peaks_q{q}d{min_dist}_top{Npeaks}_all_freq.nc')\n",
    "npeaks = ds_peaks_all['peaks_max'].sum('rank')\n",
    "npeaks_perc = npeaks / npeaks.sum('scen')\n",
    "npeaks_perc.name = 'peak_perc'\n",
    "npeaks_perc.to_netcdf(fn_peaks_all_freq)\n",
    "\n",
    "# diff\n",
    "da_wse = ds_peaks_all['WSE']\n",
    "diff_surge_seas = (da_wse.sel(scen='surge') - da_wse.sel(scen='seas')).mean('rank')\n",
    "diff_surge_seas.name = 'diff_surge_seas'\n",
    "diff_seas_tide = (da_wse.sel(scen='seas') - da_wse.sel(scen='tide')).mean('rank')\n",
    "diff_seas_tide.name = 'diff_seas_tide'\n",
    "diff_surge_tide = (da_wse.sel(scen='surge') - da_wse.sel(scen='tide')).mean('rank')\n",
    "diff_surge_tide.name = 'diff_surge_tide'\n",
    "diff = xr.merge([\n",
    "    diff_surge_seas,\n",
    "    diff_seas_tide,\n",
    "    diff_surge_tide\n",
    "])\n",
    "\n",
    "# ratio\n",
    "fn_rivmth_ts = join(ddir, 'rivmth_reanalysis.zarr')\n",
    "da_wse_peak = ds_peaks_all['WSE']\n",
    "da_wse_ts_std = xr.open_zarr(fn_rivmth_ts)['WSE'].sel(scen='surge').std('time')\n",
    "ratio = diff/da_wse_ts_std\n",
    "ratio = ratio.rename({k: k.replace('diff','ratio') for k in ratio.data_vars.keys()})\n",
    "\n",
    "# out\n",
    "fn_peaks_all_ratio = join(ddir, f'rivmth_peaks_q{q}d{min_dist}_top{Npeaks}_all_stat.nc')\n",
    "ds_out = xr.merge([diff, ratio])\n",
    "ds_out.to_netcdf(fn_peaks_all_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPs fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_rivmth_ts = join(ddir, 'rivmth_reanalysis.zarr')\n",
    "da_wse = xr.open_zarr(fn_rivmth_ts)['WSE'].sel(scen='surge')\n",
    "da_wse_std = da_wse.std('time').reset_coords(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_peaks_rp = join(ddir, f'rivmth_peaks_q{q}d{min_dist}_rp.nc')\n",
    "fn_peaks_ratio = join(ddir, f'rivmth_peaks_q{q}d{min_dist}_rp_ratio_gevfit.nc')\n",
    "da_wse_rps = xr.open_dataset(fn_peaks_rp)['WSE'] \n",
    "rps = da_wse_rps['rp'].values\n",
    "\n",
    "# ratio\n",
    "diff_surge_seas = (da_wse_rps.sel(scen='surge') - da_wse_rps.sel(scen='seas'))\n",
    "diff_surge_seas.name = 'diff_surge_seas'\n",
    "ratio_surge_seas = diff_surge_seas / da_wse_std\n",
    "ratio_surge_seas.name = 'ratio_surge_seas'\n",
    "\n",
    "diff_seas_tide = (da_wse_rps.sel(scen='seas') - da_wse_rps.sel(scen='tide'))\n",
    "diff_seas_tide.name = 'diff_seas_tide'\n",
    "ratio_seas_tide = diff_seas_tide / da_wse_std\n",
    "ratio_seas_tide.name = 'ratio_seas_tide'\n",
    "\n",
    "diff_surge_tide = (da_wse_rps.sel(scen='surge') - da_wse_rps.sel(scen='tide'))\n",
    "diff_surge_tide.name = 'diff_surge_tide'\n",
    "ratio_surge_tide = diff_surge_tide / da_wse_std\n",
    "ratio_surge_tide.name = 'ratio_surge_tide'\n",
    "\n",
    "\n",
    "ds_out = xr.merge([\n",
    "    diff_surge_seas,\n",
    "    diff_seas_tide,\n",
    "    diff_surge_tide,\n",
    "    ratio_surge_seas,\n",
    "    ratio_seas_tide,\n",
    "    ratio_surge_tide,\n",
    "])\n",
    "ds_out.to_netcdf(fn_peaks_ratio)\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPs interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.interpolate\n",
    "\n",
    "def _interp_rps(y, rps_in, rps_out, kind='linear'):\n",
    "    return sp.interpolate.interp1d(np.log10(rps_in), y, kind=kind)(np.log10(rps_out))\n",
    "\n",
    "def interp_rps(da, rps_it, rps_out, dim='rank'):    \n",
    "    ds_out = xr.apply_ufunc(\n",
    "        _interp_rps, \n",
    "        da, \n",
    "        kwargs=dict(rps_in=rps_in, rps_out=rps_out),\n",
    "        input_core_dims=[[dim]], \n",
    "        output_core_dims=[['rp']], \n",
    "        vectorize=True, \n",
    "        dask='allowed', \n",
    "        output_dtypes=[float],\n",
    "        output_sizes={'rp':rps_out.size}\n",
    "    )\n",
    "    ds_out['rp'] = xr.Variable('rp', rps_out)\n",
    "    return ds_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_peaks_rank = join(ddir, f'rivmth_peaks_q{q}d{min_dist}_top{Npeaks}_scen.nc')\n",
    "fn_peaks_ratio = join(ddir, f'rivmth_peaks_q{q}d{min_dist}_rp_ratio_interp.nc')\n",
    "ds_peaks_rank = xr.open_dataset(fn_peaks_rank, chunks={'index':500, 'rank':-1})\n",
    "da_wse = ds_peaks_rank['WSE']\n",
    "rps_in = ds_peaks_rank['rp'].values\n",
    "# rps_out = np.array([1,2,5,10])\n",
    "rps_out = rps[:-1]\n",
    "da_wse_rps = interp_rps(da_wse, rps_in, rps_out)\n",
    "\n",
    "# ratio\n",
    "diff_surge_seas = (da_wse_rps.sel(scen='surge') - da_wse_rps.sel(scen='seas'))\n",
    "diff_surge_seas.name = 'diff_surge_seas'\n",
    "ratio_surge_seas = diff_surge_seas / da_wse_std\n",
    "ratio_surge_seas.name = 'ratio_surge_seas'\n",
    "\n",
    "diff_seas_tide = (da_wse_rps.sel(scen='seas') - da_wse_rps.sel(scen='tide'))\n",
    "diff_seas_tide.name = 'diff_seas_tide'\n",
    "ratio_seas_tide = diff_seas_tide / da_wse_std\n",
    "ratio_seas_tide.name = 'ratio_seas_tide'\n",
    "\n",
    "diff_surge_tide = (da_wse_rps.sel(scen='surge') - da_wse_rps.sel(scen='tide'))\n",
    "diff_surge_tide.name = 'diff_surge_tide'\n",
    "ratio_surge_tide = diff_surge_tide / da_wse_std\n",
    "ratio_surge_tide.name = 'ratio_surge_tide'\n",
    "\n",
    "ds_out = xr.merge([\n",
    "    diff_surge_seas,\n",
    "    diff_seas_tide,\n",
    "    diff_surge_tide,\n",
    "    ratio_surge_seas,\n",
    "    ratio_seas_tide,\n",
    "    ratio_surge_tide\n",
    "])\n",
    "\n",
    "ds_out.to_netcdf(fn_peaks_ratio)\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _bootstrap(x, alphas=[0.1, 0.9], n_samples=10000):\n",
    "#     x_boot = x[np.random.randint(x.size, size=(x.size, n_samples))]\n",
    "#     x_boot_sorted = np.apply_along_axis(np.sort, arr=x_boot, axis=-1)\n",
    "#     alphas = np.atleast_1d(alphas)\n",
    "#     nvals = np.nan_to_num(np.round((n_samples-1)*alphas)).astype('int')\n",
    "#     return stat_sorted[..., nvals]\n",
    "# peaks_ranked.isel(ensemble=1, index=1).reset_coords()['water_level'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp_stats import mean_flood_day_diff, mean_flood_day_stats\n",
    "\n",
    "scens = ['surge', 'tide']\n",
    "fn_rivmth_ts = join(ddir, 'rivmth_reanalysis.zarr')\n",
    "fn_peaks_timing = join(ddir, f'rivmth_peaks_timing.nc')\n",
    "\n",
    "da_wse = xr.open_zarr(fn_rivmth_ts)['WSE'].sel(scen=scens)\n",
    "# doy_stats = mean_flood_day_stats(da_wse)\n",
    "doy_diff = mean_flood_day_diff(doy_stats['doy'].sel(scen=scens[0]), doy_stats['doy'].sel(scen=scens[1]))\n",
    "\n",
    "ds_timing = xr.merge([doy_diff, doy_stats]).reset_coords(drop=True)\n",
    "ds_timing.to_netcdf(fn_peaks_timing)\n",
    "# ds_timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## atrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_attrs_out = join(ddir, 'rivmth_mean_attrs.nc')\n",
    "\n",
    "fn_csv_coupling = join(root, 'src', '1-prepare', r'cmf_gtsm_75km_update191017.csv')\n",
    "coupling = pd.read_csv(fn_csv_coupling, index_col='index')\n",
    "\n",
    "fn_rivmth_ts = join(ddir, 'rivmth_reanalysis.zarr')\n",
    "ds_drivers = xr.open_zarr(fn_rivmth_ts).drop('WSE').mean('ensemble').sel(scen='surge').drop('scen')\n",
    "ds_drivers['Htiderange'] = (ds_drivers['Htide_day_max'] - ds_drivers['Htide_day_min'])\n",
    "ds_drivers_amax = ds_drivers[['Q', 'Hseas_day_mean', 'Hsurge_day_max', 'Hskewsurge_day', 'Htiderange']].resample(time='A').max().mean('time')\n",
    "ds_drivers_amax = ds_drivers_amax.rename({n: '{}_amax'.format(n.split('_')[0]) for n in ds_drivers_amax.data_vars.keys()})\n",
    "ds_drivers_amin = ds_drivers[['Q', 'Hseas_day_mean', 'Htiderange', 'Hskewsurge_day']].resample(time='A').min().mean('time')\n",
    "ds_drivers_amin = ds_drivers_amin.rename({n: '{}_amin'.format(n.split('_')[0]) for n in ds_drivers_amin.data_vars.keys()})\n",
    "ds_drivers_mean = ds_drivers[['Q', 'Htiderange']].mean('time')\n",
    "ds_drivers_mean = ds_drivers_mean.rename({n: '{}_mean'.format(n.split('_')[0]) for n in ds_drivers_mean.data_vars.keys()})\n",
    "\n",
    "da_wse = xr.open_zarr(fn_rivmth_ts)['WSE'].sel(scen='surge')\n",
    "da_wse_std = da_wse.std('time').reset_coords(drop=True).mean('ensemble')\n",
    "da_wse_std.name = 'wse_std'\n",
    "\n",
    "attrs = xr.merge([\n",
    "    coupling[['dist', 'dist2coast', 'rivwth', 'uparea', 'rivhgt', 'elevtn', 'gtsm_egm_offset']].to_xarray(),\n",
    "    ds_drivers_amax,\n",
    "    ds_drivers_amin,\n",
    "    ds_drivers_mean,\n",
    "    da_wse_std\n",
    "]).astype(np.float32)\n",
    "attrs.to_netcdf(fn_attrs_out)\n",
    "xr.open_dataset(fn_attrs_out).to_dataframe().to_csv(fn_attrs_out.replace('.nc','.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
