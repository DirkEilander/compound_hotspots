{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# spatial libraries\n",
    "import geopandas as gp \n",
    "\n",
    "from  shapely.geometry import Point\n",
    "import rasterio\n",
    "import rasterio.transform\n",
    "# flow direction library\n",
    "import pyflwdir # https://gitlab.com/deltares/wflow/pyflwdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read values from spatial raster\n",
    "def sample_map(x, y, fn_map, layer=1):\n",
    "    \"\"\"read map values at x, y coordinates from file\"\"\"\n",
    "    if not os.path.isfile(fn_map): \n",
    "        raise IOError(\"{} file not found\".format(fn_map))\n",
    "    with rasterio.open(fn_map, 'r') as src:\n",
    "        # assume low resolution lat lon coordinates are given\n",
    "        r, c = src.index(x, y)\n",
    "        r, c = np.atleast_1d(r).astype(int), np.atleast_1d(c).astype(int)\n",
    "        nrows, ncols = src.shape\n",
    "        valid = np.logical_and.reduce((r>=0, r<nrows, c>=0, c<ncols))\n",
    "        sample = np.ones(r.size, dtype=src.dtypes[layer-1])*np.nan\n",
    "        sample[valid] = src.read(layer)[r[valid], c[valid]]\n",
    "    return sample\n",
    "\n",
    "def sample_map_mem(x, y, map_data, transform):\n",
    "    \"\"\"read map_data (np.ndarray) values at x, y coordinates\"\"\"\n",
    "    r, c = rasterio.transform.rowcol(transform, x, y)\n",
    "    r, c = np.atleast_1d(r).astype(int), np.atleast_1d(c).astype(int)\n",
    "    nrows, ncols = map_data.shape\n",
    "    valid = np.logical_and.reduce((r>=0, r<nrows, c>=0, c<ncols))\n",
    "    sample = np.ones(r.size, dtype=map_data.dtype)*np.nan\n",
    "    sample[valid] = map_data[r[valid], c[valid]]\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read some cama-flood maps and parse flow direction data\n",
    "\n",
    "map_dir = r'/home/dirk/models/cama-flood_bmi_v3.6.2_nc/map/global_15min'\n",
    "\n",
    "fn_nextxy = join(map_dir, 'nextxy.tif')\n",
    "with rasterio.open(fn_nextxy, 'r') as src:\n",
    "    nextxy = src.read()\n",
    "    transform = src.transform\n",
    "    flw = pyflwdir.FlwdirRaster(data=nextxy, ftype='flow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulated ucat worldpop data over flow direction\n",
    "fn_exp_agg = join(map_dir, 'worldpop.tif')\n",
    "with rasterio.open(fn_exp_agg, 'r') as src:\n",
    "    exp_agg = src.read(1)\n",
    "    with rasterio.open(fn_exp_agg.replace('.tif', '_accu.tif'), 'w', **src.profile) as dst:\n",
    "        exp_agg_accu = flw.accuflux(exp_agg)\n",
    "        dst.write(exp_agg_accu.astype(np.float32), 1)\n",
    "\n",
    "fn_exp_agg_lecz = join(map_dir, 'lecz_worldpop.tif')\n",
    "with rasterio.open(fn_exp_agg_lecz, 'r') as src:\n",
    "    exp_agg_lecz = src.read(1)     \n",
    "    with rasterio.open(fn_exp_agg_lecz.replace('.tif', '_accu.tif'), 'w', **src.profile) as dst:\n",
    "        exp_agg_lecz_accu = flw.accuflux(exp_agg_lecz)\n",
    "        dst.write(exp_agg_lecz_accu.astype(np.float32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine simulations\n",
    "ddir = join(root, 'data', '3-model_output')\n",
    "scens = ['cmpnd', 'runoff']\n",
    "mods = ['anu', 'cnrs', 'ecmwf', 'jrc', 'nerc']\n",
    "rp=10\n",
    "mod_lst = []\n",
    "for mod in mods:\n",
    "    scen_lst = []\n",
    "    for scen in scens:\n",
    "        fn_swe = join(ddir, f'ev_map_sfcelv_{mod}_mswep_{scen}_v362_1980-2014.nc')\n",
    "        scen_lst.append(xr.open_dataset(fn_swe, chunks={'lat':360, 'lon':360})['sfcelv_ev'])\n",
    "    mod_lst.append(xr.concat(scen_lst, dim='scen'))\n",
    "ds = xr.concat(mod_lst, dim='ensemble')\n",
    "ds['ensemble'] = xr.Variable('ensemble', mods)\n",
    "ds['scen'] = xr.Variable('scen', scens)\n",
    "ds_diff = (ds.sel(T=rp, scen='cmpnd')-ds.sel(T=rp, scen='runoff')).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated people affected by dH\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "coupling = pd.read_csv(fn_csv_coupling2, index_col='index')\n",
    "lon, lat, index = coupling['cmf_lon_15min'], coupling['cmf_lat_15min'], coupling.index\n",
    "\n",
    "# read total exposure\n",
    "fn_exp_agg = join(map_dir, 'worldpop_accu.tif')\n",
    "fn_exp_agg_lecz = join(map_dir, 'lecz_worldpop_accu.tif')\n",
    "pop_all_rivmth = sample_map(lon, lat, fn_exp_agg)\n",
    "pop_lecz_rivmth = sample_map(lon, lat, fn_exp_agg_lecz)\n",
    "\n",
    "\n",
    "rps =[2, 10, 50, 100]\n",
    "mod_lst = []\n",
    "for mod in mods:\n",
    "    rp_lst =[]\n",
    "    for rp in rps:\n",
    "        fn_tif = join(ddir, f'{mod}_cmpnd', f'worldpop_agg_T{rp:03d}.tif')\n",
    "        \n",
    "        with rasterio.open(fn_tif, 'r') as src:\n",
    "            mv_mask = src.read(1)==src.nodata\n",
    "            \n",
    "            # accumulate total no. of people affected\n",
    "            pop_affected_all_accu = flw.accuflux(src.read(1))\n",
    "            pop_affected_all_accu[mv_mask] = src.nodata\n",
    "            pop_affected_all_rivmth = sample_map_mem(lon, lat, pop_affected_all_accu, src.transform)\n",
    "                \n",
    "            # in flood plains with larger flood depth\n",
    "            ds_diff = (ds.sel(T=rp, scen='cmpnd')-ds.sel(T=rp, scen='runoff')).compute()\n",
    "            mask = ds_diff.sel(ensemble=mod).squeeze().values>0.01   \n",
    "            pop_affected_dH = np.where(mask, src.read(1), 0)\n",
    "            pop_affected_dH_accu = flw.accuflux(pop_affected_dH)\n",
    "            pop_affected_dH_accu[mv_mask] = src.nodata\n",
    "            pop_affected_dH_rivmth = sample_map_mem(lon, lat, pop_affected_dH_accu, src.transform)\n",
    "\n",
    "            rp_lst.append(xr.merge([\n",
    "                xr.DataArray(dims=('index'), data=pop_affected_dH_rivmth, coords=dict(index=index), name='people_affected_dH'),\n",
    "                xr.DataArray(dims=('index'), data=pop_affected_all_rivmth, coords=dict(index=index), name='people_affected_all'),\n",
    "            ]))\n",
    "    mod_lst.append(xr.concat(rp_lst, dim='T'))\n",
    "ds_out = xr.merge([\n",
    "    xr.concat(mod_lst, dim='ensemble'),\n",
    "    xr.DataArray(dims=('index'), data=pop_all_rivmth, coords=dict(index=index), name='people_all'),\n",
    "    xr.DataArray(dims=('index'), data=pop_lecz_rivmth, coords=dict(index=index), name='people_lecz'),\n",
    "])\n",
    "ds_out['ensemble'] = xr.Variable('ensemble', mods)\n",
    "ds_out['T'] = xr.Variable('T', rps)\n",
    "ds_out.to_netcdf(join(ddir, 'rivmth_pop_exposed.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: delete below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exepcted annual mean people exposed\n",
    "fn_impact = join(ddir, 'rivmth_pop_affected.nc')\n",
    "ds_impact = xr.open_dataset(fn_impact)\n",
    "\n",
    "T0 = xr.DataArray(\n",
    "    dims=('ensemble', 'T', 'index'), \n",
    "    coords={'ensemble':ds_impact.ensemble, 'T': [1], 'index': ds_impact.index}, \n",
    "    data=np.zeros((ds_impact.ensemble.size,1,ds_impact.index.size))\n",
    ")\n",
    "pop_affected_dH_dp = xr.concat([T0, ds_impact['people_affected_dH']], dim='T')\n",
    "pop_affected_dH_dp['p'] = xr.Variable('T', 1/pop_affected_dH_dp['T'].values)\n",
    "pop_affected_dH_dp = pop_affected_dH_dp.sel(T=pop_affected_dH_dp['T'].values[::-1]).swap_dims({'T':'p'}) \n",
    "ds_impact['people_affected_dH_dp'] = pop_affected_dH_dp.integrate('p')\n",
    "pop_affected_all_dp = xr.concat([T0, ds_impact['people_affected_all']], dim='T')\n",
    "pop_affected_all_dp['p'] = xr.Variable('T', 1/pop_affected_all_dp['T'].values)\n",
    "pop_affected_all_dp = pop_affected_all_dp.sel(T=pop_affected_all_dp['T'].values[::-1]).swap_dims({'T':'p'}) \n",
    "ds_impact['people_affected_all_dp'] = pop_affected_all_dp.integrate('p')\n",
    "# ds_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute relative people exposed\n",
    "df = (ds_impact['people_affected_dH_dp'].sum('index')/ds_impact['people_affected_all_dp'].sum('index')*100).to_series()\n",
    "df['mean'] = df.mean()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from plot_tools import *\n",
    "import cartopy.crs as ccrs\n",
    "import seaborn as sns\n",
    "from string import ascii_uppercase as letters\n",
    "\n",
    "fdir = join(root, 'reports', 'figures')\n",
    "rc = {'savefig.bbox': 'tight',  'savefig.format': 'png', 'savefig.dpi':300}\n",
    "context = 'paper'\n",
    "# sns.set(context=context, style='whitegrid', font_scale=0.75 if context == 'talk' else 1., rc=rc)\n",
    "sns.set(context=context, style='whitegrid', font_scale=1.2 if context == 'paper' else 1., rc=rc)\n",
    "crs = ccrs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "model = 'mean'\n",
    "attrs_fn = join(ddir, 'rivmth_mean_attrs.csv')\n",
    "attrs = pd.read_csv(attrs_fn, index_col='index').rename(columns={'rivmth_lat':'lat', 'rivmth_lon':'lon'}).drop(3354)\n",
    "\n",
    "gdf = pandas2geopandas(pd.concat([\n",
    "    attrs,\n",
    "    ds_impact.mean('ensemble').sel(T=T).reset_coords(drop=True).to_dataframe()\n",
    "], axis=1))\n",
    "gdf['people_affected_dH_perc'] = gdf['people_affected_dH'] /  np.maximum(gdf['people_affected_all'],1) * 100\n",
    "gdf['people_affected_dH_dp_perc'] = gdf['people_affected_dH_dp'] /  np.maximum(gdf['people_affected_all_dp'],1) * 100\n",
    "gdf['people_affected_dH_dp_percLECZ'] = np.minimum(gdf['people_affected_dH_dp'] / np.maximum(gdf['people_lecz'],1) * 100, 100)\n",
    "gdf['people_affected_dH_dp_percALL'] = gdf['people_affected_dH_dp'] /  np.maximum(gdf['people_all'],1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins = gpd.read_file(r'/home/dirk/models/cama-flood_bmi_v3.6.2/map/global_15min/flw_basins')\n",
    "basins['area'] = basins.area\n",
    "basins['rivmth_idx'] = basins['DN'] - 1\n",
    "basins = basins.merge(gdf.drop(columns='geometry'), on='rivmth_idx', how='right')\n",
    "# fig, ax = plt.subplots(1,1, figsize=(10,5))\n",
    "# basins.plot(linewidth=0.1, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "column = f'people_affected_dH_dp'\n",
    "label=f'people affected [-]'\n",
    "vmin, vmax, n= 2, 6, 5\n",
    "cticks=np.linspace(vmin, vmax, n)\n",
    "cmap = ListedColormap(sns.cubehelix_palette(16, start=.5, rot=-.75))\n",
    "plot_kwargs=dict(edgecolor=(0.5, 0.5, 0.5, 0.8), linewidth=0.1, legend=False, zorder=2)\n",
    "\n",
    "gdf1 = basins.copy()\n",
    "if 'perc' not in column:\n",
    "    gdf1[column] = np.where(gdf1[column]<=0, 0, np.log10(gdf1[column]))\n",
    "plt.close('all')\n",
    "fig = plt.figure(figsize=(18, 10.5))\n",
    "grid = plt.GridSpec(2, 1, wspace=0.01, hspace=0.01)\n",
    "\n",
    "# map 1\n",
    "axg = fig.add_subplot(grid[0, 0], projection=crs)\n",
    "basemap(axg, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, features=['land'],)\n",
    "cax = plot_choropleth(\n",
    "    fig, axg, gdf1, column=column, \n",
    "    cmap=plt.cm.Greens , cticks=cticks, vmin=vmin, vmax=vmax, discrete=False, \n",
    "    plot_kwargs = plot_kwargs,\n",
    "    cbar_kwargs = dict(label=label, location='right'),\n",
    "    cbar_pos = dict(pad=0.02, fraction=0.01, shrink=0.5)\n",
    ")\n",
    "cax.set_yticklabels([f'$10^{e:0.0f}$' for e in cticks])\n",
    "axg.text(-175, 85, letters[0]+'', transform=crs, fontsize='large')\n",
    "    \n",
    "column = f'people_affected_dH_dp_perc'\n",
    "label=f'people affected [%]'\n",
    "vmin, vmax, n= 0, 40, 5\n",
    "cticks=np.linspace(vmin, vmax, n)\n",
    "# cmap = ListedColormap(sns.cubehelix_palette(16, start=.5, rot=-.75))\n",
    "\n",
    "# map 2\n",
    "axg2 = fig.add_subplot(grid[1, 0], projection=crs)\n",
    "basemap(axg2, bbox=(-180, -60, 180, 90), gridlines=False, outline=False, features=['land'],)\n",
    "plot_kwargs.pop('marker',None)\n",
    "plot_kwargs.pop('markersize',None)\n",
    "plot_kwargs.update(linewidth=0.1)\n",
    "cax2 = plot_choropleth(\n",
    "    fig, axg2, gdf1, column=column, \n",
    "    cmap=plt.cm.Blues, cticks=cticks, vmin=vmin, vmax=vmax, discrete=False, \n",
    "    plot_kwargs = plot_kwargs,\n",
    "    cbar_kwargs = dict(label=label, location='right'),\n",
    "    cbar_pos = dict(pad=0.02, fraction=0.01, shrink=0.5)\n",
    ") \n",
    "axg2.text(-175, 85, letters[1], transform=crs, fontsize='large')\n",
    "\n",
    "\n",
    "fn_fig = join(fdir, f'expected_annual_people_exposed_{model}.png')\n",
    "print(basename(fn_fig))\n",
    "plt.savefig(fn_fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
