{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, basename, dirname\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "# local libraries\n",
    "from cmftools import get_outlets, get_catchments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial libraries\n",
    "import geopandas as gp \n",
    "from  shapely.geometry import Point\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def sample_map(x, y, fn_map, fn_catmxy=None, layer=1):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(fn_map): \n",
    "        raise IOError(\"{} file not found\".format(fn_map))\n",
    "    with rasterio.open(fn_map, 'r') as src:\n",
    "        if fn_catmxy is None:\n",
    "            # assume low resolution lat lon coordinates are given\n",
    "            r, c = src.index(x, y)\n",
    "            r, c = np.atleast_1d(r).astype(int), np.atleast_1d(c).astype(int)\n",
    "            nrows, ncols = src.shape\n",
    "            valid = np.logical_and.reduce((r>=0, r<nrows, c>=0, c<ncols))\n",
    "        else:\n",
    "            # convert to low resolution row col using catmxy index\n",
    "            r, c, valid = model_index(x, y, fn_catmxy)\n",
    "        # if the fill domain fits into memory that's faster than using the rasterio sample function\n",
    "        sample = np.ones(r.size, dtype=src.dtypes[layer-1])*np.nan\n",
    "        sample[valid] = src.read(layer)[r[valid], c[valid]]\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update 191203"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add more metadata from CMF map derived with pyflwdir package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial libraries\n",
    "import rasterio.transform\n",
    "# flow direction library\n",
    "import pyflwdir # https://gitlab.com/deltares/wflow/pyflwdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read some cama-flood maps and parse flow direction data\n",
    "\n",
    "map_dir = r'/home/dirk/models/cama-flood_bmi_v3.6.2_nc/map/global_15min'\n",
    "\n",
    "fn_nextxy = join(map_dir, 'nextxy.tif')\n",
    "with rasterio.open(fn_nextxy, 'r') as src:\n",
    "    nextxy = src.read()\n",
    "    transform = src.transform\n",
    "    flw = pyflwdir.FlwdirRaster(data=nextxy, ftype='nextxy')\n",
    "basins = flw.basins().astype(np.int32)\n",
    "with rasterio.open(join(map_dir, 'elevtn.tif'), 'r') as src:\n",
    "    elevtn = src.read(1)\n",
    "with rasterio.open(join(map_dir, 'rivlen_grid.tif'), 'r') as src:\n",
    "    rivlen = src.read(1)\n",
    "with rasterio.open(join(map_dir, 'grarea.tif'), 'r') as src:\n",
    "    grarea = src.read(1)\n",
    "    profile = src.profile\n",
    "    \n",
    "profile.update(dtype=np.int32, nodata=-9999)\n",
    "with rasterio.open(join(map_dir, 'flw_basins.tif'), 'w', **profile) as dst:\n",
    "    dst.write(basins, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read simulation (meta) data\n",
    "root = r'/scratch/compound_hotspots/'\n",
    "ddir = join(root, 'data', '4-postprocessed')\n",
    "\n",
    "fn_csv_coupling = join(root, 'src', '1-prepare', r'cmf_gtsm_75km_update191017.csv')\n",
    "fn_csv_coupling2 = join(root, 'src', '1-prepare', r'cmf_gtsm_75km_update191203.csv')\n",
    "\n",
    "coupling = pd.read_csv(fn_csv_coupling, index_col='index')\n",
    "lon, lat = coupling['cmf_lon_15min'], coupling['cmf_lat_15min']\n",
    "sample_dict = {}\n",
    "sample_dict['basin_idx'] = join(map_dir, 'flw_basins.tif')\n",
    "for name in sample_dict:\n",
    "    coupling[name] = sample_map(lon, lat, sample_dict[name]).astype(np.int)\n",
    "coupling_sel.to_csv(fn_csv_coupling2, float_format='%.6f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update 191019\n",
    "fix selections of stations with too large uparea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing error in uparea of earlier files\n",
    "root = r'/scratch/compound_hotspots'\n",
    "ddir = join(root, 'data')\n",
    "fn_csv_coupling = join(root, 'src', '1-prepare', r'cmf_gtsm_75km.csv')\n",
    "fn_csv_coupling2 = join(root, 'src', '1-prepare', r'cmf_gtsm_75km_update191017.csv')\n",
    "fn_csv_rivmth = join(root, 'src', '1-prepare', r'rivmth_upa1e+09_dist1e+04_update191017.csv')\n",
    "\n",
    "rivmth = pd.read_csv(fn_csv_rivmth, index_col=0).drop(columns=['col_15min', 'row_15min', 'lat_15min', 'lon_15min'])\n",
    "coupling = pd.read_csv(fn_csv_coupling, index_col='rivmth_idx').drop(columns=['cmf_col_15min', 'cmf_row_15min'])\n",
    "coupling_sel = coupling.reindex(rivmth.index.values).dropna(axis=0)\n",
    "rivmth_sel = rivmth.reindex(coupling_sel.index)\n",
    "for col in rivmth.columns:\n",
    "    coupling_sel[col] = rivmth_sel[col]\n",
    "coupling_sel['rivwth'] = np.round(coupling_sel['rivwth'],0)\n",
    "coupling_sel['dist'] = np.round(coupling_sel['dist'],0)\n",
    "coupling_sel = coupling_sel.reset_index()\n",
    "for name in ['couple_id', 'gtsm_idx', 'rivwth', 'rivmth_idx', 'dist']:\n",
    "    coupling_sel[name] = coupling_sel[name].astype(int)\n",
    "coupling_sel = coupling_sel.set_index('couple_id').sort_index()\n",
    "coupling_sel.index.name = 'index'\n",
    "coupling_sel.to_csv(fn_csv_coupling2, float_format='%.6f')\n",
    "# coupling_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write list with locations which are incorrectly used\n",
    "fn_csv_coupling2 = join(root, 'src', '1-prepare', r'cmf_gtsm_75km_update191017_wrong.csv')\n",
    "coupling = pd.read_csv(fn_csv_coupling, index_col='rivmth_idx').drop(columns=['cmf_col_15min', 'cmf_row_15min'])\n",
    "\n",
    "idx_false = [idx for idx in coupling.index if idx not in rivmth.index]\n",
    "coupling_false = coupling.reindex(idx_false).dropna(axis=0).drop(columns=['uparea', 'rivwth'])\n",
    "coupling_false['dist'] = np.round(coupling_false['dist'],0)\n",
    "coupling_false = coupling_false.reset_index()\n",
    "for name in ['couple_id', 'gtsm_idx', 'rivmth_idx', 'dist']:\n",
    "    coupling_false[name] = coupling_false[name].astype(int)\n",
    "coupling_false = coupling_false.set_index('couple_id').sort_index()\n",
    "coupling_false.index.name = 'index'\n",
    "coupling_false.to_csv(fn_csv_coupling2, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve CMF outlet locations and sample attributes (uparea, elevtn, dist2coast) from map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get outlets\n",
    "outlets = get_outlets(fn_nextxy, fn_lonlat, sample_dict={}, fn_out=fn_outlets_all, res_str='15min')\n",
    "print(len(outlets))\n",
    "outlets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dir = r'/home/dirk/models/cama-flood_bmi_v3.6.2_nc/map/global_15min'\n",
    "NE_dir = r'/home/dirk/datasets/NaturalEarth'\n",
    "# I/O\n",
    "fn_nextxy = join(map_dir, \"nextxy.tif\")\n",
    "fn_lonlat = join(map_dir, \"lonlat.tif\")\n",
    "fn_outlets_all = join(map_dir, 'rivmth_all.txt')\n",
    "# sample metadata from\n",
    "names = ['uparea', 'rivwth', 'rivhgt', 'elevtn']\n",
    "sample_dict = {name: join(map_dir, \"{}.tif\".format(name)) for name in names}\n",
    "sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn_outlets = join(map_dir, 'rivmth.txt')\n",
    "min_uparea=1e9 # 1000 km2\n",
    "max_dist=10e3 # 10km\n",
    "fn_outlets = join(map_dir, 'rivmth_upa{:.0e}_dist{:.0e}.txt'.format(min_uparea, max_dist))\n",
    "\n",
    "outlets = pd.read_csv(fn_outlets, index_col=0)\n",
    "#15 min res\n",
    "lon, lat = outlets['lon_15min'], outlets['lat_15min']\n",
    "for name in sample_dict:\n",
    "    outlets[name] = sample_map(lon, lat, sample_dict[name])\n",
    "# highres\n",
    "lon, lat = outlets['lon'], outlets['lat']\n",
    "outlets['dist2coast'] = sample_map(lon, lat, join(NE_dir, 'ne_10m_dist2coast_eucl_1min.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filter\n",
    "min_uparea=1e9 # 1000 km2\n",
    "max_dist=10e3 # 10km\n",
    "fn_outlets = join(map_dir, 'rivmth_upa{:.0e}_dist{:.0e}_update191017.csv'.format(min_uparea, max_dist))\n",
    "outlets_select = outlets[np.logical_and(outlets['uparea'].values>min_uparea, outlets['dist2coast'].values<max_dist)]\n",
    "outlets_select['uparea'] = outlets_select['uparea'] / 1e6\n",
    "outlets_select.to_csv(fn_outlets, float_format='%.6f')\n",
    "\n",
    "# outlets_select['uparea'] = outlets_select['uparea'] / 1e6\n",
    "outlets_select.sort_values(by='uparea', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
