{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook\n",
    "- resamples the worlpop 30' grid to 18'', the CMF downscaled flood depth grid resolution\n",
    "- converts the 18' worldpop geoptif to CMF binary files for each highres area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.transform import array_bounds, from_bounds, from_origin\n",
    "from rasterio.warp import Resampling\n",
    "from rasterio.crs import CRS\n",
    "from os.path import join, isfile\n",
    "import numpy as np\n",
    "import math\n",
    "from numba import vectorize, njit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_to_coords(affine, shape):\n",
    "    \"\"\"Returs a raster axis with pixel center coordinates based on the affine.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    affine : affine transform\n",
    "        Two dimensional affine transform for 2D linear mapping\n",
    "    shape : tuple of int\n",
    "        The height, width  of the raster.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x, y coordinate arrays : tuple of ndarray of float\n",
    "    \"\"\"\n",
    "    height, width = shape\n",
    "    x_coords, _ = affine * (np.arange(width) + 0.5, np.zeros(width) + 0.5)\n",
    "    _, y_coords = affine * (np.zeros(height) + 0.5, np.arange(height) + 0.5)\n",
    "    return x_coords, y_coords\n",
    "\n",
    "def reggrid_area(lats, lons):\n",
    "    \"\"\"returns a the cell area for a regular grid with cell centres lats & lons [m2]\"\"\"\n",
    "    xres = np.abs(np.mean(np.diff(lons)))\n",
    "    yres = np.abs(np.mean(np.diff(lats)))\n",
    "    return cellarea(lats, xres, yres)[:,None]*np.ones((lats.size,lons.size), dtype=lats.dtype)\n",
    "\n",
    "@vectorize([\n",
    "    \"float64(float64,float64,float64)\", \n",
    "    \"float32(float32,float32,float32)\"\n",
    "    ])\n",
    "def cellarea(lat, xres, yres):\n",
    "    \"\"\"returns the area of cell with a given resolution (resx,resy) at a given cell center latitude [2]\"\"\"\n",
    "    _R = 6371e3 # Radius of earth in m. Use 3956e3 for miles\n",
    "    l1 = math.radians(lat-abs(yres)/2.)\n",
    "    l2 = math.radians(lat+abs(yres)/2.)\n",
    "    dx = math.radians(xres)\n",
    "    return _R**2*dx*(math.sin(l2) - math.sin(l1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resample worldpop grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN\n",
    "wp_fn = r'/home/dirk/datasets/WorldPop/ppp_2010_1km_Aggregated.tif'\n",
    "with rasterio.open(wp_fn, 'r') as src:\n",
    "    print(src.profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_tot_pop = 0\n",
    "# with rasterio.open(wp_fn, 'r') as src:\n",
    "#     for ji, wdw in src.block_windows(1):\n",
    "#         pop_30sec = src.read(1, window=wdw)\n",
    "#         src_tot_pop += np.nansum(pop_30sec[pop_30sec!=src.nodata])\n",
    "# src_tot_pop\n",
    "src_tot_pop = 6812530928.509598\n",
    "dst_tot_pop_nearest = 6810460454.075542\n",
    "dst_tot_pop_bilinear = 6812976189.401252\n",
    "err_bil = np.abs(1-dst_tot_pop_bilinear/src_tot_pop)*100  \n",
    "err_nn = np.abs(1-dst_tot_pop_nearest/src_tot_pop)*100\n",
    "err_bil, err_nn, dst_tot_pop_bilinear-src_tot_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out\n",
    "xmin, ymin, xmax, ymax = -180, -72, 180, 84\n",
    "xsize, ysize = 0.005, 0.005\n",
    "blockxsize, blockysize = 400, 400\n",
    "wp2_fn = r'/home/dirk/datasets/WorldPop/ppp_2010_18arcsec_Aggregated_nearest.tif'\n",
    "\n",
    "tot_pop = 0\n",
    "# ppp to density \n",
    "wpd_fn = wp_fn.replace('.tif', '_density.tif')\n",
    "with rasterio.open(wp_fn, 'r') as src:\n",
    "    prof = src.profile.copy()\n",
    "    prof.update(\n",
    "        transform = from_origin(xmin, ymax, xsize, ysize),\n",
    "        width = int((xmax-xmin) / xsize),\n",
    "        height = int((ymax-ymin) / xsize),\n",
    "        blockxsize = blockxsize,\n",
    "        blockysize = blockysize,\n",
    "    )\n",
    "    with rasterio.open(wp2_fn, 'w', **prof) as dst:\n",
    "        for ji, dst_wdw in dst.block_windows(1):\n",
    "#             if not np.all(ji == (10, 10)): continue\n",
    "            \n",
    "            # get window properties dst (18sec)\n",
    "            dst_transform = dst.window_transform(dst_wdw)\n",
    "            dst_shape = dst_wdw.height, dst_wdw.width\n",
    "            dst_bounds = array_bounds(*dst_shape, transform=dst_transform)\n",
    "            \n",
    "            # get src window  (30sec)\n",
    "            src_wdw = rasterio.windows.round_window_to_full_blocks(\n",
    "                window=rasterio.windows.from_bounds(*dst_bounds, transform=src.transform), \n",
    "                block_shapes=src.block_shapes\n",
    "            )\n",
    "\n",
    "            # read pop\n",
    "            pop_30sec = src.read(1, window=src_wdw)\n",
    "            \n",
    "            # convert to density\n",
    "            src_transform = src.window_transform(src_wdw)\n",
    "            src_bounds = array_bounds(*pop_30sec.shape, transform=src_transform)\n",
    "            src_lons, src_lats = affine_to_coords(src_transform, pop_30sec.shape[1], pop_30sec.shape[0])\n",
    "            area_30sec = reggrid_area(src_lats, src_lons) #km\n",
    "            dens_30sec = np.where(pop_30sec != src.nodata, pop_30sec / area_30sec, src.nodata)\n",
    "            assert np.all(np.isfinite(dens_30sec))\n",
    "            \n",
    "            # resample\n",
    "            dens_18sec = np.ones(dst_shape)*dst.nodata\n",
    "            rasterio.warp.reproject(\n",
    "                source=dens_30sec,\n",
    "                destination=dens_18sec,\n",
    "                resampling=Resampling.nearest,\n",
    "                src_transform=src_transform,\n",
    "                src_crs=src.crs,\n",
    "                src_nodata=src.nodata,\n",
    "                dst_transform=dst_transform,\n",
    "                dst_height=dst_wdw.height, \n",
    "                dst_width=dst_wdw.width,\n",
    "                dst_crs=dst.crs,\n",
    "                dst_nodata=dst.nodata\n",
    "            )\n",
    "            assert np.all(np.isfinite(dens_18sec))\n",
    "            # to pop per pixel\n",
    "            dst_lons, dst_lats = affine_to_coords(dst_transform, dst_wdw.width, dst_wdw.height)\n",
    "            area_18sec = reggrid_area(dst_lats, dst_lons)\n",
    "            pop_18sec = np.where(dens_18sec!=dst.nodata, dens_18sec * area_18sec, dst.nodata)\n",
    "            tot_pop += pop_18sec[pop_18sec!=src.nodata].sum()\n",
    "            # write\n",
    "            dst.write(pop_18sec.astype(np.float32), window=dst_wdw, indexes=1)\n",
    "print(tot_pop)\n",
    "print(tot_pop/src_tot_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write to binary files for fortran impact routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdir = r'/home/dirk/models/CaMa-Flood_v3.6.2/map/global_15min'\n",
    "fn_regions = join(mdir,'hires', 'location.txt')\n",
    "regions = pd.read_csv(fn_regions, delim_whitespace=True, index_col=0).T \\\n",
    "            .set_index('area').astype(float).to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "\n",
    "wp2_fn = r'/home/dirk/datasets/WorldPop/ppp_2010_18arcsec_Aggregated_bilinear.tif'\n",
    "\n",
    "for area in regions:\n",
    "    fn = join(mdir, 'hires', f'{area}.catmxy.tif')\n",
    "    fn_out_bin = join(mdir, 'hires', f'{area}.worldpop')\n",
    "    if isfile(fn_out_bin): continue\n",
    "    print(area)\n",
    "    with rasterio.open(fn, 'r') as like:\n",
    "        bounds = like.bounds\n",
    "        # xarray to deal with si2 which passes -180 line\n",
    "        ds = xr.open_rasterio(wp2_fn, chunks={'x':400, 'y':400}).drop('band').squeeze()\n",
    "        mv = ds.attrs['nodatavals'][0]\n",
    "        w, s, e, n = bounds\n",
    "        if e > 180 or w < -180:\n",
    "            lon_org = np.copy(ds['x'].values)\n",
    "            if e > 180:\n",
    "                ds['x'] = xr.Variable('x', np.where(lon_org < 0, lon_org + 360, lon_org))\n",
    "            else:\n",
    "                ds['x'] = xr.Variable('x', np.where(lon_org > 0, lon_org - 360, lon_org))\n",
    "            ds = ds.sortby('x')\n",
    "        pop = ds.sel({'x':slice(w, e), 'y':slice(n, s)}).values\n",
    "        ds.close()\n",
    "        assert np.all(pop.shape == like.shape)\n",
    "        np.where(pop!=mv, pop, 0).astype(np.float32).tofile(fn_out_bin) # mv zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum exposure at unit catchment level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def sum_exp_ucat(catmx, catmy, flddif, exp, lecz, elevtn, exp_agg, exp_agg_lecz):\n",
    "    \"\"\"sum exposure at unit catchment level\"\"\"\n",
    "    ny, nx = catmx.shape\n",
    "    NY, NX = exp_agg.shape\n",
    "    for iy in range(ny):\n",
    "        for ix in range(nx):\n",
    "            if catmx[iy, ix]>0:\n",
    "                r, c = catmy[iy, ix]-1, catmx[iy, ix]-1\n",
    "#                 assert r>=0 and r<NY and c>=0 and c<NX\n",
    "                exp0 = exp[iy, ix]\n",
    "                if exp0 <= 0: continue\n",
    "                exp_agg[r,c] += exp0\n",
    "                if elevtn[r,c] + flddif[iy, ix] < 10 and lecz[r,c]:\n",
    "                    exp_agg_lecz[r,c] += exp0\n",
    "    return exp_agg, exp_agg_lecz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodata=-9999.\n",
    "bbox = -180., -90., 180., 90.\n",
    "res = 0.25\n",
    "NX, NY = 1440, 720\n",
    "profile = {\n",
    "    'driver': 'GTiff', \n",
    "    'dtype': 'float32', \n",
    "    'nodata': nodata, \n",
    "    'width': ((bbox[2]-bbox[0])/res), \n",
    "    'height': ((bbox[3]-bbox[1])/res), \n",
    "    'count': 1, \n",
    "    'crs': CRS.from_epsg(4326), \n",
    "    'transform': from_origin(bbox[0], bbox[3], res, res),\n",
    "    'compress': 'lzw', \n",
    "    'interleave': 'band'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dir = r'/home/dirk/models/cama-flood_bmi_v3.6.2_nc/map/global_15min'\n",
    "\n",
    "fn_regions = join(map_dir, 'hires', 'location.txt')\n",
    "regions = pd.read_csv(fn_regions, delim_whitespace=True, index_col=0).T \\\n",
    "            .set_index('area').astype(float).to_dict(orient='index')\n",
    "\n",
    "# high res maps\n",
    "fn_flddif = join(map_dir, 'hires', '{}.flddif').format\n",
    "fn_catmxy = join(map_dir, 'hires', '{}.catmxy').format\n",
    "fn_exp = join(map_dir, 'hires', '{}.worldpop').format\n",
    "\n",
    "# model res maps\n",
    "fn_elevtn = join(map_dir, 'elevtn.bin')\n",
    "with open(fn_elevtn, 'r') as fid:\n",
    "    elevtn = np.fromfile(fid, 'f4').reshape(NY, NX)\n",
    "fn_lecz = join(map_dir, 'lecz_10m_basin.tif')\n",
    "with rasterio.open(fn_lecz, 'r') as src:\n",
    "    lecz = np.logical_and(src.read(1)>0, src.read(1)!=src.nodata)\n",
    "\n",
    "# out maps\n",
    "fn_exp_agg = join(map_dir, 'worldpop.tif')\n",
    "fn_exp_agg_lecz = join(map_dir, 'lecz_worldpop.tif')\n",
    "exp_agg = np.zeros((NY, NX))\n",
    "exp_agg_lecz = np.zeros((NY, NX))\n",
    "\n",
    "for area in regions.keys():\n",
    "    ny, nx = int(regions[area]['ny']), int(regions[area]['nx'])\n",
    "    with open(fn_flddif(area), 'r') as fid:\n",
    "        flddif = np.fromfile(fid, 'f4').reshape(ny, nx)\n",
    "    with open(fn_catmxy(area), 'r') as fid:\n",
    "        catmx, catmy = np.fromfile(fid, 'i2').reshape(2, ny, nx)\n",
    "    with open(fn_exp(area), 'r') as fid:\n",
    "        exp = np.fromfile(fid, 'f4').reshape(ny, nx)\n",
    "        \n",
    "    exp_agg, exp_agg_lecz = sum_exp_ucat(catmx, catmy, flddif, exp, lecz, elevtn, exp_agg, exp_agg_lecz)\n",
    "    print(area, exp_agg[exp_agg!=-9999].sum()/1e6)\n",
    "\n",
    "with rasterio.open(fn_exp_agg, 'w', **profile) as dst:\n",
    "    exp_agg[elevtn==elevtn[0,0]] = nodata\n",
    "    dst.write(exp_agg.astype(np.float32), 1)\n",
    "with rasterio.open(fn_exp_agg_lecz, 'w', **profile) as dst:\n",
    "    exp_agg_lecz[elevtn==elevtn[0,0]] = nodata\n",
    "    dst.write(exp_agg_lecz.astype(np.float32), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sum exposure at unit catchment level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def sum_exp_ucat(catmx, catmy, flddif, exp, lecz, elevtn, exp_agg, exp_agg_lecz):\n",
    "    \"\"\"sum exposure at unit catchment level\"\"\"\n",
    "    ny, nx = catmx.shape\n",
    "    NY, NX = exp_agg.shape\n",
    "    for iy in range(ny):\n",
    "        for ix in range(nx):\n",
    "            if catmx[iy, ix]>0:\n",
    "                r, c = catmy[iy, ix]-1, catmx[iy, ix]-1\n",
    "#                 assert r>=0 and r<NY and c>=0 and c<NX\n",
    "                exp0 = exp[iy, ix]\n",
    "                if exp0 <= 0: continue\n",
    "                exp_agg[r,c] += exp0\n",
    "                if elevtn[r,c] + flddif[iy, ix] < 10 and lecz[r,c]:\n",
    "                    exp_agg_lecz[r,c] += exp0\n",
    "    return exp_agg, exp_agg_lecz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodata=-9999.\n",
    "bbox = -180., -90., 180., 90.\n",
    "res = 0.25\n",
    "NX, NY = 1440, 720\n",
    "profile = {\n",
    "    'driver': 'GTiff', \n",
    "    'dtype': 'float32', \n",
    "    'nodata': nodata, \n",
    "    'width': ((bbox[2]-bbox[0])/res), \n",
    "    'height': ((bbox[3]-bbox[1])/res), \n",
    "    'count': 1, \n",
    "    'crs': CRS.from_epsg(4326), \n",
    "    'transform': from_origin(bbox[0], bbox[3], res, res),\n",
    "    'compress': 'lzw', \n",
    "    'interleave': 'band'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dir = r'/home/dirk/models/cama-flood_bmi_v3.6.2_nc/map/global_15min'\n",
    "\n",
    "fn_regions = join(map_dir, 'hires', 'location.txt')\n",
    "regions = pd.read_csv(fn_regions, delim_whitespace=True, index_col=0).T \\\n",
    "            .set_index('area').astype(float).to_dict(orient='index')\n",
    "\n",
    "# high res maps\n",
    "fn_flddif = join(map_dir, 'hires', '{}.flddif').format\n",
    "fn_catmxy = join(map_dir, 'hires', '{}.catmxy').format\n",
    "fn_exp = join(map_dir, 'hires', '{}.worldpop').format\n",
    "\n",
    "# model res maps\n",
    "fn_elevtn = join(map_dir, 'elevtn.bin')\n",
    "with open(fn_elevtn, 'r') as fid:\n",
    "    elevtn = np.fromfile(fid, 'f4').reshape(NY, NX)\n",
    "fn_lecz = join(map_dir, 'lecz_10m_basin.tif')\n",
    "with rasterio.open(fn_lecz, 'r') as src:\n",
    "    lecz = np.logical_and(src.read(1)>0, src.read(1)!=src.nodata)\n",
    "\n",
    "# out maps\n",
    "fn_exp_agg = join(map_dir, 'worldpop.tif')\n",
    "fn_exp_agg_lecz = join(map_dir, 'lecz_worldpop.tif')\n",
    "exp_agg = np.zeros((NY, NX))\n",
    "exp_agg_lecz = np.zeros((NY, NX))\n",
    "\n",
    "for area in regions.keys():\n",
    "    ny, nx = int(regions[area]['ny']), int(regions[area]['nx'])\n",
    "    with open(fn_flddif(area), 'r') as fid:\n",
    "        flddif = np.fromfile(fid, 'f4').reshape(ny, nx)\n",
    "    with open(fn_catmxy(area), 'r') as fid:\n",
    "        catmx, catmy = np.fromfile(fid, 'i2').reshape(2, ny, nx)\n",
    "    with open(fn_exp(area), 'r') as fid:\n",
    "        exp = np.fromfile(fid, 'f4').reshape(ny, nx)\n",
    "        \n",
    "    exp_agg, exp_agg_lecz = sum_exp_ucat(catmx, catmy, flddif, exp, lecz, elevtn, exp_agg, exp_agg_lecz)\n",
    "    print(area, exp_agg[exp_agg!=-9999].sum()/1e6)\n",
    "\n",
    "with rasterio.open(fn_exp_agg, 'w', **profile) as dst:\n",
    "    exp_agg[elevtn==elevtn[0,0]] = nodata\n",
    "    dst.write(exp_agg.astype(np.float32), 1)\n",
    "with rasterio.open(fn_exp_agg_lecz, 'w', **profile) as dst:\n",
    "    exp_agg_lecz[elevtn==elevtn[0,0]] = nodata\n",
    "    dst.write(exp_agg_lecz.astype(np.float32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out = xr.open_dataset(join(ddir, r'rivmth_swe_am_ci.nc')).sel(scen=['surge', 'seas', 'tide']).load()\n",
    "ds_out.close()\n",
    "ds_out = ds_out.rename({'WSE_am': 'annual_maxima', 'WSE_ev': 'extreme_values', 'WSE_ev_ci': 'extreme_values_ci'})\n",
    "ds_out['annual_maxima'].attrs = dict(\n",
    "    description='simulated annual maxima of water surface elevation at the river mouth',\n",
    "    unit='m+EGM96',\n",
    "    long_name='water_surface_elevation'\n",
    ")\n",
    "ds_out['extreme_values'].attrs = dict(\n",
    "    description='extreme values of water surface elevation at the river mouth based on Gubmel distribion of annual maxima',\n",
    "    unit='m+EGM96',\n",
    "    long_name='water_surface_elevation'\n",
    ")\n",
    "ds_out['extreme_values_ci'].attrs = dict(\n",
    "    description='confidence intervals around extreme values of water surface elevation',\n",
    "    unit='m+EGM96',\n",
    "    long_name='water_surface_elevation'\n",
    ")\n",
    "ds_out['params'].attrs = dict(\n",
    "    description='parameters of Gumbel extreme value distibution',\n",
    "    unit='-',\n",
    ")\n",
    "ds_out.attrs.update(\n",
    "    institution = 'Institute for Environmental Studies (IVM) - Vrije Universiteit Amsterdam',\n",
    "    author = 'Dirk Eilander (dirk.eilander@vu.nl)',\n",
    "    date_created = str(datetime.now().date()),\n",
    "    history = f'created using s03-rivmth_ev; xarray v{xr.__version__}',\n",
    ")\n",
    "ds_out.to_netcdf(join(ddir, r'rivmth_wse_ev.nc'))\n",
    "ds_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
